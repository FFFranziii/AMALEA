{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Inhaltsstoffe: Kann Spuren von Intelligenz enthalten"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Faltungsoperation\n", "\n", "Wie der Name schon sagt, macht die Faltungsschicht (engl. convolutional layer) Gebrauch von Faltungen. Als kurze Zusammenfassung fasst dieses kleine Widget die Faltung von zwei rechteckigen Funktionen zusammen. Die Faltungsoperation ist durch die folgende Gleichung im kontinuierlichen Bereich gegeben:\n", "\n", "\\begin{equation*}\n", "x(t) \\ast y(t) = \\langle x(t - \\tau), y^{\\ast}(\\tau) \\rangle_{\\tau} = \\int_{-\\infty}^{+\\infty} x(t -\\tau) y(\\tau) d \\tau\n", "\\end{equation*}"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["from ipywidgets import interact, interactive, fixed, interact_manual\n", "import numpy as np\n", "from PIL import Image\n", "import matplotlib.pyplot as plt\n", "from scipy import signal\n", "figure_inches = 10\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["def convolution(tau:tuple, width1:tuple, width2:tuple):\n", "    \n", "    x1 = np.linspace(-3.5, 3.5, num = 1000)\n", "    dX = x1[1] - x1[0]    \n", "    rect1 = np.where(abs(x1) <= width1/2 , 1, 0)\n", "    rect2 = np.where(abs(x1- tau)<= width2/2 , 1, 0)\n", "    \n", "    # Convolution of rect1 and rect2\n", "    conv = np.convolve(rect1, rect2, 'same') * dX \n", "    \n", "    \n", "    # Plotting\n", "    plt.figure(1, figsize=(16.5,3.5))\n", "    plt.plot(x1, rect1, 'b', label = '$rect_{1}$(t)')\n", "    plt.plot(x1, rect2, 'r', label = '$rect_{2}$(t- $\\\\tau$)')\n", "    x_gr = x1 - tau\n", "    if tau <=0:\n", "        index = np.where((np.absolute(x_gr)-np.absolute(tau))<=0.004)\n", "        index = index[0][0]\n", "    else:\n", "        index = np.where(np.absolute(x_gr-tau)<=0.004)\n", "        if not index[0].size > 0:\n", "            index = [[999]]\n", "        index = index[0][0]\n", "    plt.plot(x_gr[:index]  , conv[:index], 'g', label = '$rect_{1}$ $\\\\ast$ $rect_{2}$')\n", "    plt.axvline(x = tau, color= 'r', dashes = [6,2])\n", "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., prop={'size':15})\n", "    plt.ylim(0,np.maximum(np.max(conv),np.max(rect1))+0.1)\n", "    plt.xlim(-2.5, 2.5)\n", "    plt.grid()\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Interactive Plot\n", "interactive_plot = interactive(convolution, tau = (-2.0, +2.0, 0.25), \n", "                               width1 = (0.25, 1.75, 0.25), \n", "                               width2 = (0.25, 1.75, 0.25))\n", "output = interactive_plot.children[-1]\n", "interactive_plot"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Nat\u00fcrlich erfolgt die Berechnung der Faltung nicht im kontinuierlichen Bereich. Daher verwendet numpy die folgende Formel f\u00fcr diskrete Faltung im 1-dimensionalen Raum:\n", "\n", "\\begin{equation*}\n", "x_n \\ast y_n = \\sum_{i = -\\infty}^{\\infty} x_i  \\  y_{n-i} = \\sum_{i = -\\infty}^{\\infty} y_{i}  \\ x_{n-i}\n", "\\end{equation*}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Filter und Faltung in der Bildverarbeitung\n", "\n", "Die Faltungsoperation kann auch in zwei Dimensionen angegeben werden:\n", "\n", "\\begin{equation*}\n", "x_{mn} \\ast \\ast \\ y_{mn} = \\sum_{i = -\\infty}^{\\infty} \\sum_{j = -\\infty}^{\\infty} x_{ij}  \\  y_{m-i, n-j} = \\sum_{i = -\\infty}^{\\infty} \\sum_{j = -\\infty}^{\\infty} y_{ij}  \\ x_{m-i, n-j}\n", "\\end{equation*}\n", "\n", "In Bezug auf die Faltung von Bildern im diskreten Bereich \u00e4ndern sich die Grenzen zu endlichen Werten, die die Gr\u00f6\u00dfe der Bildform entsprechen.\n", "Diese Operation kann dann wie folgt visualisiert werden:\n", "\n", "\n", "<img src=\"images/Faltung1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n", "<img src=\"images/Faltung2.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n", "<img src=\"images/Faltung3.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n", "<img src=\"images/Faltung4.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n", "\n", "\n", "Beachten Sie, dass die Faltungsschicht den Filter nicht spiegelt, wie in der konventionellen Signalverarbeitung. Von nun an werden Bilder oder r\u00e4umliche Informationen in 3 Dimensionen definiert durch:\n", "\n", " - Height $H$\n", " - Weight $W$\n", " - Depth $d$ (channels)\n", " \n", "Die diskrete Faltung reduziert die Bilddimensionen wie oben beschrieben. Die folgende Gleichung beschreibt die Reduktion selbst, wobei $K$ die `Kernel`- oder Filterdimensionen, $P$ zus\u00e4tzliche Werte (meist zur Erhaltung der Ausgangsdimensionen, genannt `Padding`) und $S$ den `Stride` bezeichnet. Es gibt verschiedene Padding-Techniken, z.B. das Hinzuf\u00fcgen von Nullen (Zero Padding). Wenn der Stride gr\u00f6\u00dfer als 1 ist, \u00fcberspringt der Kernel bei der Faltung dazwischen liegende Werte.\n", "\n", "\\begin{align}\n", "W_{i+1} = \\dfrac{(W_{i}-K_{x}+2*P_{x})}{S_x}+1 \\\\\n", "H_{i+1} = \\dfrac{(H_{i}-K_{y}+2*P_{y})}{S_y}+1 \n", "\\end{align}\n", "\n", "\n", "Zun\u00e4chst beginnen wir mit einem **grauen Bild** namens ascent, wobei W gleich der Breite des Bildes und H gleich der H\u00f6he des Bildes ist. Da dieses Bild ein Graustufenbild ist, ist die Tiefe $d=1$."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 5.2.1:</b> \n", "Implementieren Sie die Funktion <code>conv</code> welche ein gegebenes Bild <code>image_data</code> mit einem gegebenenen Filter <code>filter_kern</code> filtert. Nehmen Sie an:\n", "\n", "* Das Bild liegt entsprechend dem Beispiel (in der folgenden Zelle) als eine Liste von Listen vor\n", "* Die Tiefe des Bildes ist 1\n", "</div>"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["def conv(image_data:list, filter_kern:list)->list:\n", "    # STUDENT CODE HERE\n", "\n", "    #STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["test_input_data = [[0,0,0,0,0], [0,1,1,1,0], [0,0,2,0,0], [0,3,3,3,0], [0,0,0,0,0], [0,0,0,0,0]]\n", "test_filter = [[0,0], [-1, 1]]\n", "test_result = [[1,0,0,-1],[0,2,-2,0],[3,0,0,-3], [0,0,0,0], [0,0,0,0]]\n", "found = conv(test_input_data, test_filter)\n", "# Die folgende Zeile erzeugt einen Fehler, wenn die Ausgabe der Methode nicht mit der erwarteten \u00fcbereinstimmt \n", "assert found == test_result"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Filtertypen\n", "\n", "Bevor wir nun in Richtung praktische Anwendung gehen, schauen wir uns grundlegende Filter an. Au\u00dferdem werden wir uns die Effekte der Filter anschauen - hierzu verwenden wir das folgende Bild:"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["def read_image_as_array(image_path:str, new_size: tuple) -> np.array:\n", "    img = Image.open(image_path).convert('L')\n", "    img = img.resize(new_size,Image.ANTIALIAS)\n", "    return np.array(img)\n", "    \n", "lama = Image.open('images/lama.png').convert('L')\n", "lama = lama.resize((500,500),Image.ANTIALIAS)\n", "plt.figure(figsize=(figure_inches, figure_inches))\n", "plt.imshow(lama, cmap='gray')\n", "data = np.array(lama)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Identit\u00e4tsfilter\n", "\n", "Der erste Filter entspricht der Identit\u00e4t, d.h. der Wert eines Pixel wird auf genau diesen abgebildet. Um dies zu erreichen wird ein quadratischer Filterkernel ben\u00f6tigt, dessen Gr\u00f6\u00dfe ungerade ist. Au\u00dferdem ist der mittlere Eintrag 1 und alle anderen 0. Ein $3\\times 3$-Filterkernel hat somit die Form:\n", "\n", "$\\left\\lbrack\\begin{array}{ccc} 0&0&0\\\\ 0&1&0\\\\ 0&0&0\\end{array}\\right\\rbrack$\n", "\n", "Und nun die angek\u00fcndigte Anwendung auf das Bild:"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(figure_inches, figure_inches))\n", "filter_kern_id = [[0,0,0],[0,1,0],[0,0,0]]\n", "filtered_data = conv(data, filter_kern_id)\n", "plt.imshow(filtered_data, cmap='gray')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Eckendetektoren\n", "\n", "Die n\u00e4chsten drei Filter ziehlen darauf ab, Ecken im Bild zu finden. Ziel hierbei ist es fl\u00e4chige Bereiche voneinander zu trennen. Die Filter sind oft nach deren Erfinder bzw. Entdecker benannt. In diesem Fall stellt der Sobel2 eine Verbesserung des Sobel1 dar - dieser kann zus\u00e4tzlich zum horizontalen sowie vertikalen auch im $45^\\circ$ Bereich messen.\n", "\n", "Roberts: $\\left\\lbrack\\begin{array}{ccc} 1&0&-1\\\\ 0&0&0\\\\ -1&0&1 \\end{array}\\right\\rbrack$\n", "\n", "Sobel1: $\\left\\lbrack\\begin{array}{ccc} 0&-1&0\\\\ -1&4&-1\\\\ 0&-1&0\\end{array}\\right\\rbrack$\n", "\n", "Sobel2: $\\left\\lbrack\\begin{array}{ccc} -1&-1&-1\\\\-1&8&-1\\\\ -1&-1&-1\\end{array}\\right\\rbrack$"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["filter_kern_roberts = [[1,0,-1], [0,0,0], [-1,0,1]]\n", "\n", "plt.figure(figsize=(figure_inches, figure_inches))\n", "data = read_image_as_array('images/lama.png', (500,500))\n", "filtered_data_e1 = conv(data, filter_kern_roberts)\n", "\n", "plt.imshow(filtered_data_e1, cmap='gray')"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["filter_kern_sobel1 = [[0,-1,0], [-1,4,-1], [0,-1,0]]\n", "\n", "plt.figure(figsize=(figure_inches, figure_inches))\n", "data = read_image_as_array('images/lama.png', (500,500))\n", "filtered_data = conv(data, filter_kern_sobel1)\n", "\n", "plt.imshow(filtered_data, cmap='gray')"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["filter_kern_sobel2 = [[-1,-1,-1], [-1,8,-1], [-1,-1,-1]]\n", "\n", "plt.figure(figsize=(figure_inches, figure_inches))\n", "data = read_image_as_array('images/lama.png', (500,500))\n", "filtered_data = conv(data, filter_kern_sobel2)\n", "\n", "plt.imshow(filtered_data, cmap='gray')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Bildsch\u00e4rfen\n", "\n", "Der n\u00e4chste Filter dient, wie der Name bereits vermuten l\u00e4sst, dazu, dass Konturen im Bild sch\u00e4rfer werden.\n", "\n", "$\\left\\lbrack\\begin{array}{ccc} 0&-1&0\\\\ -1&5&-1\\\\ 0&-1&0 \\end{array}\\right\\rbrack$"]}, {"cell_type": "code", "execution_count": 11, "metadata": {"scrolled": true}, "outputs": [], "source": ["filter_kern_sharp = [[0,-1,0], [-1,5,-1], [0,-1,0]]\n", "\n", "plt.figure(figsize=(figure_inches, figure_inches))\n", "data = read_image_as_array('images/lama.png', (500,500))\n", "filtered_data = conv(data, filter_kern_sharp)\n", "\n", "plt.imshow(filtered_data, cmap='gray')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Blur / Unsch\u00e4rfe\n", "\n", "Die letzen beiden Filter dienen dazu, das Bild zu gl\u00e4tten. Der erste Filter wird auch als Box-Linear-Filter bezeichnet und ist verh\u00e4tlinism\u00e4\u00dfig relativ simple aufgebaut. Der zweite Filter basiert auf einer Gau\u00dfverteilung und wird daher als Gau\u00df-Filter bezeichnet.\n", "\n", "Box-Linear-Filter: $\\frac{1}{9} \\left\\lbrack\\begin{array}{ccc}1&1&1\\\\ 1&1&1\\\\ 1&1&1\\end{array}\\right\\rbrack$\n", "\n", "Gau\u00df-Filter: $\\frac{1}{16} \\left\\lbrack\\begin{array}{ccc}1&2&1\\\\ 2&4&2\\\\ 1&2&1\\end{array}\\right\\rbrack$"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": ["filter_kern_blf = [[1/9, 1/9, 1/9], [1/9, 1/9, 1/9], [1/9, 1/9, 1/9]]\n", "\n", "plt.figure(figsize=(figure_inches, figure_inches))\n", "data = read_image_as_array('images/lama.png', (500,500))\n", "filtered_data = conv(data, filter_kern_blf)\n", "\n", "plt.imshow(filtered_data, cmap='gray')"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["filter_kern_gauss = [[1/16, 2/16, 1/16], [2/16, 4/16, 2/16], [1/16, 2/16, 1/16]]\n", "\n", "plt.figure(figsize=(figure_inches, figure_inches))\n", "data = read_image_as_array('images/lama.png', (500,500))\n", "filtered_data = conv(data, filter_kern_gauss)\n", "\n", "plt.imshow(filtered_data, cmap='gray')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### RGB-Bilder\n", "\n", "Farbige Bilder k\u00f6nnen in der Regel durch RGB-Bilder dargestellt werden, wobei $d$ gleich 3 ist und enth\u00e4lt:\n", "\n", "- R (rot), \n", "- G (gr\u00fcn),\n", "- B (blau)\n", "\n", "Werte f\u00fcr alle Pixel in einem Bild."]}, {"cell_type": "code", "execution_count": 14, "metadata": {"scrolled": true}, "outputs": [], "source": ["lama = Image.open('images/lama.png')\n", "lama = np.array(lama)\n", "\n", "fig, ax = plt.subplots(figsize=(figure_inches, figure_inches))\n", "ax.set_title('Lama image 768x1024', fontsize = 15)\n", "ax.imshow(lama, interpolation='nearest')\n", "plt.tight_layout()"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["# In general deep learning (and in tensorflow) Conv-layers will \n", "# regard all channels and therefore use \"cubic\" filter\n", "\n", "# The filter used here in the example down below is only using d=1 (two - dimensional) of the \n", "# rgb image (therefore red), you can change [:,:,0] to [:,:,1] (green) and [:,:,2] (blue)!\n", "# Try it! :)\n", "\n", "prewitt_x =  np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n", "\n", "lama_x_prew = signal.convolve2d(lama[:,:,0], prewitt_x, boundary='symm', mode='same')\n", "lama_x_prew = np.absolute(lama_x_prew)\n", "\n", "fig, ax = plt.subplots(figsize=(figure_inches, figure_inches))\n", "ax.set_title('Horizontale Ableitung des Lama Bildes', fontsize = 15)\n", "ax.imshow(lama_x_prew, interpolation='nearest', cmap='gray')\n", "plt.tight_layout()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Die Faltungsschicht (engl. Convolutional Layer)\n", "\n", "<img src=\"images/featuremaps.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n", "\n", "Eine Faltungsschicht, welche die erste Schicht im Netzwerk sein k\u00f6nnte, ist im Bild oben dargestellt. Ihr Kernel oder Filter mit den Dimensionen $K_x \\times K_y \\times d$ enth\u00e4lt Gewichte, die w\u00e4hrend des Trainings aktualisiert werden und auch die Darstellung der Bilder ver\u00e4ndern. Eine Aktivierungskarte (engl. activation map) entspricht einer Faltungsoperation mit einem bestimmten Filter und dem zugeh\u00f6rigen Eingangsbild oder den r\u00e4umlichen Daten der vorherigen Schicht. In den meisten F\u00e4llen werden nicht nur ein, sondern mehrere Filter in einer Faltungsschicht gelernt, so dass es mehrere Aktivierungskarten gibt. In diesem speziellen Fall scheint die Ausgabegr\u00f6\u00dfe dieser Faltungsschicht im Vergleich zur Eingabegr\u00f6\u00dfe gr\u00f6\u00dfer geworden zu sein. Infolgedessen werden h\u00e4ufig Pooling-Operationen angeh\u00e4ngt, um die Daten innerhalb des Netzwerks zu reduzieren. Die n\u00e4chste Schicht erh\u00e4lt dann wieder r\u00e4umliche Informationen und verwendet Filter, um die r\u00e4umlichen Informationen zu extrahieren und zu ver\u00e4ndern.\n", "\n", "\n", "**Idea**: _`Sp\u00e4rliche Verbindungen (engl. Sparse Connections)` (nicht vollst\u00e4ndig verbundene Schichten wie bei einem MLP) sind als Kernel f\u00fcr gro\u00dfe Datenstrukturen gegeben. Die Anzahl der lernbaren Gewichte sinkt!_\n", "\n", "Vergleichen wir eine standardm\u00e4\u00dfige voll verbundene Schicht (engl. fully connected layer) eines MLP mit einer Faltungsschicht f\u00fcr ein regul\u00e4res farbiges Bild der Gr\u00f6\u00dfe $256\\times256\\times3$:\n", "- Erstes Hidden Layer in einer voll verbundenen Schicht:\n", "    - Input Neuronen $\\rightarrow$ $256*256*3$\n", "    - Beginnen Sie z. B. mit der H\u00e4lfte der Neuronen im ersten Hidden Layer $\\rightarrow$ $128*256*3$\n", "    - Ergebnisse in Gewichte und Biases $\\rightarrow$ $256*256*3*128*256*3 + 128*256*3 = 19.327.451.136$ Parameters\n", "\n", "        \n", "- Erste Faltungsschicht in einem faltigen neuronalen Netz: Standard 256 Filter (vern\u00fcnftige Gr\u00f6\u00dfe) der Gr\u00f6\u00dfe $3\\times3\\times3$ \n", "    - Gewichte und Biases $\\rightarrow$ $256 * 3 * 3 *3 + 256 = 7.168 $ Parameters\n", "    \n", "Trotzdem brauchen Faltungen mit r\u00e4umlichen Bl\u00f6cken wie in der obigen Abbildung noch Zeit, um verarbeitet zu werden.\n", "Lokale Informationen werden nur nicht wie globale Abh\u00e4ngigkeiten in Hidden Layers verwendet!\n", "\n", "Die **Vorteile** einer Faltungsschicht (`CONV`) gegen\u00fcber einer vollverkn\u00fcpften Schicht sind die folgenden\n", " - Weniger Parameter f\u00fcr das Training\n", " - Nutzung der lokalen Strukturen des Bildes\n", " - Unabh\u00e4ngig von der Position des Merkmals im Bild\n", " \n", "**Nachteile** von Faltungsschichten (`CONV`):\n", " - Informationen m\u00fcssen r\u00e4umliche Abh\u00e4ngigkeiten haben (wie bei einem menschlich erkennbaren Bild)\n", "\n", "Beim Stapeln mehrerer Faltungsschichten hat ein Kernel der folgenden Faltungsschicht die Form $K_x \\times K_y \\times d$, wobei $d$ die Anzahl der Kan\u00e4le der vorherigen Schicht ist. Die Anzahl der Kan\u00e4le ist gegeben durch die Anzahl der verschiedenen Filter, die in der Faltungsschicht verwendet werden. Definiert man also eine Faltungsschicht mit z. B. $nb\\_filters=64$, so legt man die dritte Dimension eines Filters in der n\u00e4chsten Schicht fest. Denn im zweidimensionalen Fall expandiert der Filter immer auf die vorherige Kanaldimension. Betrachtet man CNNs f\u00fcr die Videoanalyse oder f\u00fcr Zeitreihen, so st\u00f6\u00dft man auf 3-dimensionale Faltungsschichten, die sich nicht nur in den Bilddimensionen bewegen, sondern in einer dritten Dimension (in diesem Fall: Zeit). "]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Die Poolingsschicht (engl. pooling layer)\n", "\n", "<img src=\"images/maxpool.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n", "\n", "\n", "                                     Quelle: http://cs231n.github.io/convolutional-networks/\n", "\n", "\n", "Die Pooling Schicht ist ein Filter wie alle anderen Filter im neuronalen Faltungsnetzwerk. Allerdings mit der Ausnahme, dass sie ihre Gewichte nicht aktualisiert und eine feste Funktionsoperation durchf\u00fchrt. Die h\u00e4ufigste Pooling-Operation ist das Max-Pooling. Wie der Name schon sagt, wird im Bereich des Kerns nur der Maximalwert weitergegeben. Normalerweise entspricht der Stride den Dimensionen des Kernels. Das Max-Pooling wird nur auf die H\u00f6he und Breite des Bildes angewendet, so dass die Kanaldimensionen nicht betroffen sind. Es wird verwendet, um r\u00e4umliche Informationen zu reduzieren."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 5.2.2:</b> Implementieren Sie die Funktion <code>max_pool</code> die Maxpooling durchf\u00fchrt. Gegeben ist wieder ein Grauwertbild <code>image_data</code>, d.h. es besitzt nur einen Kanal und Sie k\u00f6nnen annehmen, dass das Bilder wieder als eine Liste von Listen \u00fcbergeben wird. Au\u00dferdem ist die Gr\u00f6\u00dfe des Filters <code>filter_size</code> als Tupel und die <code>stride</code> als <code>int</code> gegeben.\n", "</div>"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["def max_pool(image_data:list, filter_size:tuple, stride:int)->list:\n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["test_input_data = [[0,0,0,0,0], [0,1,1,1,0], [0,0,2,0,0], [0,3,3,3,0], [0,0,0,0,0], [0,0,0,0,0]]\n", "test_filter_size = (2,2)\n", "stride = 2\n", "test_result = [[1,1],[3,3], [0,0]]\n", "\n", "# The folgende Zeile erzeugt einen Fehler, wenn die Ausgabe der Methode nicht mit der erwarteten \u00fcbereinstimmt \n", "found = max_pool(test_input_data, test_filter_size, stride)\n", "assert found == test_result"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### ReLU - Schicht oder Aktivierung\n", "Die \"RELU\"-Schicht oder Aktivierung verwendet eine elementweise Aktivierungsfunktion auf das Raumvolumen an, wie auf jeden Knoten in einer Hidden Layer. Die Funktion kann als $max(0,x)$ angegeben werden und ist unten dargestellt. Betrachten Sie $\\sigma(x)$ als die Aktivierungsfunktion."]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "def relu(x:float)->float:\n", "    return np.maximum(0,x)\n", "x = np.linspace(-10, 10, num = 1000)\n", "\n", "plt.figure(2, figsize=(10,3.5))\n", "plt.plot(x, relu(x), label='ReLU')\n", "plt.title('The ReLU activation')\n", "plt.legend()\n", "plt.xlabel('x')\n", "plt.ylabel('$\\sigma(x)$')\n", "plt.tight_layout()\n", "plt.grid()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Zusammenfassung\n", "\n", "Die folgende Animation zeigt recht gut, wie ein Faltungsnetzwerk (engl. convolutional network) anhand des `MNIST`-Datensatzes funktioniert.\n", "Nachdem die Faltungsschichten die Repr\u00e4sentation der Bilder ver\u00e4ndert haben, werden die endg\u00fcltigen mehrdimensionalen Bl\u00f6cke in ein langes Array gelegt (die Operation wird \"Flattening\" genannt) und an voll verbundene Schichten eines neuronalen Netzes weitergeleitet.\n", "\n", "[MNIST-CLassification](http://scs.ryerson.ca/~aharley/vis/conv/flat.html)\n", "\n", "#### Receptive Field\n", "\n", "In der Animation bzw. Simulation von MNIST werden Abh\u00e4ngigkeiten, die als Linien zwischen mehr als zwei Schichten dargestellt werden, nicht abgebildet.\n", "Dennoch ist es m\u00f6glich, Beziehungen zwischen beliebigen Schichten innerhalb des Netzes darzustellen. Dadurch ist es m\u00f6glich, ein gewisses Wissen oder eine Idee \u00fcber die Anzahl der Faltungsschichten zu erhalten, die f\u00fcr eine Anwendung oder Aufgabe verwendet werden sollten. Betrachten Sie drei \u00fcbereinander gestapelte Faltungsschichten wie im Bild unten. Ein Wert in der gr\u00fcnen Schicht bezieht sich auf 9 Eingangswerte. Folglich summiert sich ein Wert in der gelben Schicht auf 9 in der gr\u00fcnen Schicht. Ein Eintrag in der gelben Schicht wird also von mehr Werten beeinflusst als die gr\u00fcnen Aktivierungseintr\u00e4ge in Bezug auf das Eingangsbild. Dieser Bereich ist gelb dargestellt und deckt 49 Werte des Eingangsbildes ab. Um die Dimensionen w\u00e4hrend der Faltungen wie in \u00fcblichen CNNs beizubehalten, wurde ein Padding verwendet, um die Dimensionen der Matrix gleich zu halten. Die `Initialmatrix` ist dann von der Gr\u00f6\u00dfe $7 \\times 7$.\n", "\n", "<img src=\"images/ReceptiveField.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n", "\n", "    Quelle:https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 5.2.3:</b> Was ist der Hauptunterschied zwischen einer Faltungsschicht (engl. convolutional layer) und einer vollverkn\u00fcpften Schicht (engl. fully-connected layer) und warum werden \u00fcberhaupt Filter verwendet?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.10"}}, "nbformat": 4, "nbformat_minor": 4}