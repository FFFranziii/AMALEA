{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Willkommen in der Baumschule!   "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Einf\u00fchrung\n", "\n", "Entscheidungsb\u00e4ume sind die Bausteine einer der leistungsst\u00e4rksten Methoden des **\u00fcberwachten Lernens** (z. B. mit einer vordefinierten Zielvariablen), die heute verwendet werden. Falls Sie bereits eine Fehlerdiagnose bei einem Ger\u00e4t, einem Auto oder einem Computer durchf\u00fchren mussten, ist es gut m\u00f6glich, dass Sie schon einmal einem Flussdiagramm zur Fehlerbehebung begegnet sind. Flussdiagramme sind visuelle Darstellungen von Entscheidungsb\u00e4umen. Zum Beispiel ver\u00f6ffentlicht die Higher School of Economics Informationsdiagramme, um das Leben ihrer MitarbeiterInnen zu erleichtern. Hier ist ein Ausschnitt aus der Anleitung f\u00fcr die Ver\u00f6ffentlichung eines Papers im Portal der Hochschule. \n", "<img src=\"images/snipped_GER.png\">"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Klassifizierungs- und Regressionsb\u00e4ume (CART)\n", "\n", "Classification and Regression Trees (Klassifizierungs- und Regressionsb\u00e4ume) ist ein Akronym, das 1984 von Leo Breiman eingef\u00fchrt wurde. Es bezeichnet Entscheidungsbaum-Algorithmen, die f\u00fcr pr\u00e4diktive Modellierungsprobleme verwendet werden k\u00f6nnen. Wir werden uns in dieser \u00dcbung auf den CART-Algorithmus konzentrieren."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### CART\n", "\n", "Das CART-Modell wird in Form eines bin\u00e4reren Entscheidungsbaums dargestellt. Dabei handelt es sich um den gleichen bin\u00e4ren Baum, den Sie vielleicht von Algorithmen und Datenstrukturen kennen. Jeder Knoten des Bin\u00e4rbaums kann null, einen oder zwei Kindknoten haben.\n", "\n", "Ein Knoten repr\u00e4sentiert eine einzelne Eingabevariable (X) und einen Aufteilungspunkt (engl. split point) auf dieser Variable (vorausgesetzt, die Variable ist numerisch). Die Blatt- oder Endknoten des Baums enthalten eine Ausgangsvariable (Y), die f\u00fcr eine Vorhersage verwendet wird. \n", "\n", "Beim Erstellen eines bin\u00e4ren Entscheidungsbaums wird der Eingaberaum aufgeteilt. Dazu wird das sogenannte rekursive bin\u00e4re Splitting verwendet (greedy Ansatz). Hierbei handelt es sich um ein numerisches Verfahren, bei dem alle Werte aneinandergereiht werden und verschiedene Aufteilungspunkte mit Hilfe einer Kostenfunktion ausprobiert und bewertet werden.\n", "\n", "Der Split mit den besten Kosten (niedrigste Kosten, da wir die Kosten minimieren) wird ausgew\u00e4hlt. Alle Eingangsvariablen und alle m\u00f6glichen Aufteilungspunkte werden ausgewertet und auf Grundlage der Kostenfunktion (greedy) ausgew\u00e4hlt.\n", "\n", "- **Regression:** Die Kostenfunktion, die zum Finden der Splitpunkte minimiert wird, ist die **Summe des quadrierten Fehlers** \u00fcber alle Trainingsstichproben, die in das Rechteck fallen.\n", "\n", "- **Klassifizierung:** Es wird die *Gini*-Kostenfunktion verwendet, die einen Hinweis darauf liefert, wie rein die Knoten sind. Die Knotenreinheit bezieht sich dabei darauf, wie gemischt die jedem Knoten zugewiesenen Trainingsdaten sind.\n", "\n", "Die Aufteilung wird fortgesetzt, bis die Knoten eine Mindestanzahl von Trainingsbeispielen enthalten oder eine maximale Baumtiefe erreicht ist.\n", "\n", "In dieser Aufgabe konzentrieren wir uns nur auf die Klassifizierungseigenschaft des Algorithmus."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Metriken\n", "\n", "#### Gini-Index\n", "\n", "Der Gini-Index ist die Kostenfunktion, die zum Bewerten der Aufteilungen des Datensatzes verwendet wird. Eine Aufteilung umfasst ein Eingabeattribut und einen Wert f\u00fcr dieses Attribut. Der Gini-Score gibt eine Vorstellung davon, wie gut eine Aufteilung ist, da er angibt, wie gemischt die Klassen in den beiden Gruppen sind, die durch die Aufteilung entstanden sind. Eine perfekte Aufteilung ergibt einen Gini-Score von 0, w\u00e4hrend die schlechteste Aufteilung, z. B. eine 50/50-Aufteilung, f\u00fcr ein Zwei-Klassen-Problem einen Gini-Score von 0,5 ergibt.\n", "\n", "Die Berechnung des Gini-Scores l\u00e4sst sich am besten anhand eines Beispiels demonstrieren:\n", "\n", "<img src=\"images/iris_tree.png\">\n", "\n", "Angenommen, Sie finden eine Irisbl\u00fcte und wollen sie klassifizieren. In der obigen Abbildung beginnen wir im *Wurzelknoten*: Dieser Knoten \u00fcberpr\u00fcft, ob die L\u00e4nge des Bl\u00fctenblatts kleiner als 2,45 cm ist. Wenn das der Fall ist, gehen wir zum linken Kindknoten der Wurzel hinunter. Dieser Knoten ist ein *Blattknoten*, da er keine Kinder besitzt. \n", "\n", "Nehmen wir nun an, wir finden eine weitere Blume. Diese besitzt eine Bl\u00fctenblattl\u00e4nge, die gr\u00f6\u00dfer als 2,45 cm ist. Angefangen bei der Wurzel kommen wir so zum rechten Kindknoten, der kein Blattknoten ist. Dieser Knoten m\u00f6chte wissen, ob die Breite des Bl\u00fctenblatts kleiner als 1,75 cm ist. Wenn das der Fall ist, dann ist unsere Blume h\u00f6chstwahrscheinlich eine Iris-Versicolor. Andernfalls handelt es sich wahrscheinlich um eine Iris-Virginica.\n", "\n", "Angenommen, wir haben 100 Trainingsinstanzen mit einer Bl\u00fctenblattl\u00e4nge gr\u00f6\u00dfer als 2,45 cm, darunter 54 mit einer Bl\u00fctenblattbreite kleiner als 1,75 cm. Das Wertattribut eines Knotens gibt an, auf wie viele Trainingsinstanzen jeder Klasse dieser Knoten zutrifft: Der Knoten unten rechts trifft auf 0 Iris-Setosa, 1 Iris-Versicolor und 45 Iris-Virginica zu. Gem\u00e4\u00df Gleichung (\\ref{eq1}) setzt sich der Gini-Score wie folgt zusammen: $1-(0/54)^2-(49/54)^2-(5/54)^2 = 0.168$.\n", "\n", "\\begin{equation*}\n", "G_i = 1 - \\sum_{k=0}^{n-1} p_{i,k}^2\n", "\\label{eq1}\\tag{1}\n", "\\end{equation*}\n", "wobei $p_{i,k}$ das Verh\u00e4ltnis der Instanzen der Klasse k unter den Trainingsinstanzen im $i^{th}$-Knoten beschreibt."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Importe"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "\n", "%matplotlib inline\n", "\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Entscheidungsb\u00e4ume mit scikit-learn\n", "\n", "Nun haben wir unseren Datensatz f\u00fcr die Algorithmen des maschinellen Lernens vorbereitet. Zu Beginn haben wir die Idee der Klassifizierung und Regression mit Entscheidungsb\u00e4umen beschrieben. Im Folgenden werden wir die Implementierung von Entscheidungsb\u00e4umen mittels scikit-learn verwenden, um die bin\u00e4re Klassifizierung des Titanic Datensatzes durchzuf\u00fchren.\n", "\n", "\n", "## Entscheidungsb\u00e4ume ohne Parameteroptimierung (engl. parameter tuning)\n", "\n", "#### Importieren der Bibliotheken\n", "Der erste Schritt besteht darin, den Algorithmus \"wie er ist\" zu verwenden, ohne irgendwelche Parameter anzupassen. Importieren Sie daher die notwendige Bibliothek/Funktion von scikit-learn, die den DecisionTreeClassifier enth\u00e4lt. Au\u00dferdem muss die Funktion export_graphviz importiert werden, die f\u00fcr die Darstellung der Ergebnisse der Entscheidungsb\u00e4ume ben\u00f6tigt wird. Um das Modell zu evaluieren, m\u00fcssen wir ein Train- und ein Validation-Set erzeugen, indem wir den train-test split von scikit-learn verwenden. Importieren Sie daher die notwendigen Funktionen. Um die Performance der trainierten Entscheidungsb\u00e4ume zu vergleichen, m\u00fcssen wir zun\u00e4chst den DummyClassifier importieren. Der DummyClassifer https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html ist in der Lage, Datenpunkte gleichm\u00e4\u00dfig zuf\u00e4llig zu klassifizieren oder immer das h\u00e4ufigste Label im Trainingssatz vorherzusagen. Importieren Sie den accuracy score des Pakets 'metrics' f\u00fcr die Evaluierung der Klassifizierungsergebnisse."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.1:</b> Importieren Sie die im Text oben genannten Funktionen.\n", "</div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-info\">\n", "<b>Hinweis:</b> Falls graphviz nicht installiert ist, versuchen Sie folgende Schritte.  \n", "<ul>\n", "<li> 1. Ansatz: \u00d6ffnen Sie anaconda, anschlie\u00dfend gehen Sie zu den Umgebungen (engl. environments) und w\u00e4hlen Sie diejenige aus, an der Sie gerade arbeiten. Suchen Sie dann nach graphviz und installieren Sie es.\n", "<li> 2. Ansatz: \u00d6ffnen Sie ein Terminal innerhalb Ihrer Umgebung, indem Sie auf den gr\u00fcnen Pfeil Ihrer Umgebung klicken. Anschlie\u00dfend:\n", "<ul>\n", "<li> Aktivieren Sie Ihre Umgebung: conda activate environment_name\n", "    <li> Installieren Sie pip: conda install pip (gegebenfalls bereits installiert)\n", "    <li> installieren Sie graphviz: conda install python-graphviz\n", "    </ul>\n", "</li>\n", "\n", "</ul>\n", "<br>\n", "\n", "</div>"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE\n", "\n", "from graphviz import Source"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Generieren von Training-, Validierung- und Test-Datensatz\n", "\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.2:</b> \n", "<ul>\n", "<li>Laden Sie die Datens\u00e4tze aus der L\u00f6sung der Vorbereitungsdatei (train_prepared.csv,...).\n", "<li>Nehmen Sie die Spalte mit den Labeldaten sowohl im Trainingsatz als auch im Testsatz und entfernen diese vom Datensatz. \n", "<li>Teilen Sie den \"train\"-Teil des Datensatzes in 80 % Trainingsdaten und 20 % Validierungsdaten auf. Verwenden Sie den Parameter random_state = 17 f\u00fcr die Reproduzierbarkeit der Ergebnisse.\n", "<li> Hinweis: Sie k\u00f6nnten den originalen Trainigsatz f\u00fcr das Kreuzvalidierungsverfahren (engl. Cross Validation) sp\u00e4ter ben\u00f6tigen. \n", "</ul>\n", "    \n", "<b>Wichtige Information:</b> Beim \u00fcberwachten Lernen bestehen die Datens\u00e4tze immer aus Labels und Features. Nachdem Sie Ihr Modell trainiert haben, geben Sie ihm neue Input Datens\u00e4tze, die Features (Alter, Geschlecht usw.) enthalten; es gibt das vorhergesagte Label ('Survived') f\u00fcr diese Person zur\u00fcck.<br>\n", "</div>"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Validierung des Dummy Klassifikators\n", "\n", "Um einen Eindruck zu bekommen, ob die Klassifizierung mit dem Modell sinnvoll ist, verwenden wir den DummyClassifier, der zuf\u00e4llig entscheidet.  \n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.3:</b> \n", "<ul>\n", "<li> Trainieren Sie den Klassifikator mit dem entsprechenden Parameterwert 'most_frequent' f\u00fcr die Strategie\n", "<li> Benutzen Sie den Parameter random_state = 17 (f\u00fcr die Reproduzierbarkeit der Ergebnisse)\n", "<li> Berechnen Sie die Korrektklassifikationsrate (engl. accuracy), um die Klassifizierungsgenauigkeit f\u00fcr die Validierungsdaten zu erhalten\n", "<li> Hinweis: Besuchen Sie die Website von scikit-learn, um den Klassifikator zu importieren, ihn zu trainieren, mit ihm Vorhersagen zu treffen und die Korrektklassifikationsrate zu berechnen\n", "</ul>\n", "</div>"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 3.2.4:</b> Wie interpretieren Sie dieses Ergebnis? \n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Validierung des Entscheidungsbaums\n", "\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.5:</b> \n", "<ul>\n", "<li> Trainieren Sie einen Entscheidungsbaum (mit DecisionTreeClassifier) mit einer maximalen Tiefe von 2\n", "<li> Evaluieren Sie die Korrektklassifikationsrate Metrik (engl. accuracy metric) anhand der Validierungsdaten. \n", "<li> Benutzen Sie den Parameter random_state = 17 f\u00fcr die Reproduzierbarkeit der Ergebnisse.\n", "<li> Hinweis: Syntax oder Funktionen mit diesem Klassifikator sind f\u00fcr Training etc. gleich.\n", "    </li>\n", "    \n", "</ul>\n", "</div>"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 3.2.6:</b>  Was k\u00f6nnen Sie beobachten, wenn wir die Korrektklassifikationsrate mit der des DummyClassifiers vergleichen?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Das trainierte Modell verstehen\n", "\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.7:</b> \n", "<ul>\n", "<li> Plotten Sie den Baum mit sklearn.tree.export_graphviz und graphviz\n", "<li> Geben Sie die Namen der Features sowie die Klassennamen entsprechend dem Datensatz aus.\n", "<li> Hinweis: Benutzen Sie dataframe.columns.values und Source(export_graphviz)\n", "</ul>\n", "</div>"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 3.2.8:</b>  Welche Features werden f\u00fcr Vorhersagen im erstellten Entscheidungsbaum verwendet? Welche der verbleibenden Splits (in der letzten Zeile des Baums) ist derzeit die Pr\u00e4ziseste?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Testen der Generalisierung\n", "\n", "In den vorherigen Aufgaben haben wir die Performance unseres Algorithmus an einem einzelnen Train-Test-Split unseres Training-Datensatzes evaluiert. Lassen Sie uns nun die Kreuzvalidierung (engl. cross validation) verwenden, um eine bessere Sch\u00e4tzung des Generalisierungsfehlers zu erhalten.\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.9:</b> Importieren Sie die notwendige Bibliothek f\u00fcr die Kreuzvalidierung (engl. cross validation) mit StratifiedKFold.\n", "</div>"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.10:</b> \n", "<ul>\n", "<li> F\u00fchren Sie eine 5-fache geschichtete Kreuzvalidierung (engl. 5-fold stratified cross validation) durch\n", "<li> Berechnen Sie die mittlere Korrektklassifikationsrate (engl. mean accuracy) und die Standardabweichung der Korrektklassifikationsrate (engl. accuracy)\n", "<li> Verwenden Sie eine maximale Tiefe von 2 und random_state = 17 f\u00fcr den Baum und die Folds\n", "<li> Vergessen Sie nicht, den gesamten Trainingssatz zu verwenden (bevor Sie ihn in train,val aufteilen)\n", "</ul>\n", "</div>"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Parameteroptimierung f\u00fcr Entscheidungsb\u00e4ume\n", "\n", "Der wichtigste Parameter eines Entscheidungsbaums ist die Tiefe des Baums. Daher ist es notwendig, verschiedene Tiefen des Baums zu evaluieren, um die optimale Leistung hinsichtlich der Korrektklassifikationsrate (engl. classification accuracy) zu erreichen. Zu diesem Zweck verwenden wir die Gittersuche (engl. grid search) in Kombination mit dem Kreuzvalidierungsverfahren (engl. cross validation), das wir zuvor verwendet haben. Gl\u00fccklicherweise hat scikit-learn bereits eine sch\u00f6ne und einfach zu bedienende Schnittstelle f\u00fcr dieses Problem implementiert. Die Funktion hei\u00dft `GridSearchCV` und ist in der Bibliothek sklearn.model_selection zu finden. \n", "\n", "\n", "#### Verwendung von Grid Search Cross-Validation zur Optimierung der Baumtiefe\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.11:</b> \n", "<ul>\n", "<li> Laden Sie die Bibliothek GridSearchCV und trainieren Sie einen Entscheidungsbaum (DecisionTreeClassifier, random_state = 17)\n", "<li> Ermitteln Sie die optimale maximale Tiefe mit 5-facher geschichteter Kreuzvalidierung (engl. 5-fold stratified cross-validation) und gleichem RandomState \n", "<li> Variieren Sie die Tiefe des Baums zwischen 1 und 13.\n", "<li> Vergessen Sie nicht, den gesamten Trainingssatz zu verwenden (bevor Sie ihn in train,val aufteilen)\n", "<li> Hinweis: Verwenden Sie die scikit-learn-Website f\u00fcr weitere Informationen zu den Funktionen\n", "</ul>\n", "</div>"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.12:</b> \n", "<ul>\n", "<li> Zeichnen Sie ein Diagramm zur Darstellung der durchschnittlichen Korrektklassifikationsrate \u00fcber die Tiefe \n", "<li> Benutzen Sie das Attribut <code>.cv_results</code>, um die durchschnittliche Korrektklassifikationsrate mit Hilfe von 'mean_test_score' zu erhalten.\n", "</ul>\n", "</div>"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 3.2.13:</b>  Was sind die besten Parameterwerte? Wie hoch ist die Korrektklassifikationsrate (Kreuzvaliderungsverfahren) des Modells mit dieser Baumtiefe?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["F\u00fcr unsere Trainingsdaten haben wir den optimalen Parameter gefunden. Schlie\u00dflich k\u00f6nnen wir die Perfomance bewerten, indem wir unsere Trainingsdaten zum Trainieren und unseren Testdatensatz zum Testen verwenden. Verwenden Sie im Folgenden immer eine Baumtiefe von 3. \n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.14:</b> \n", "<ul>\n", "<li> Trainieren Sie einen Entscheidungsbaum bei einer Baumtiefe von drei, unter Verwendung aller Trainingsdaten (keine Kreuzvalidierung)\n", "<li> Berechnen Sie die Korrektklassifikationsrate (engl. accuracy) f\u00fcr den Testdatensatz. Verwenden Sie den Parameter random_state = 17 f\u00fcr die Reproduzierbarkeit.\n", "</ul>\n", "</div>\n"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["dot_data = export_graphviz(\n", "    decision_tree, out_file=None, feature_names=x_train.columns.values, class_names=['Dead','Survived'],  filled=True,\n", "    rounded=True, special_characters=True\n", ")  \n", "graph = Source(dot_data)\n", "graph "]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Vergleich von Ergebnissen mit der nicht optimierten Version\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.15:</b> Bestimmen Sie die Wirkung von GridSearchCV\n", "<ul>\n", "<li> Benutzen Sie folgenden Ausdruck: (acc2 - acc1) / acc1 * 100%\n", "<li> acc1 und acc2 sind die Korrektklassifikationsrate (engl. accuracies) der Kreuzvalidierung vor und nach der Optimierung von max_depth mit GridSearchCV \n", "<li> Hinweis: acc1 wurde bereits vor der Optimierung verwendet, berechnen Sie daher acc2 zum Vergleich\n", "<li> Geben Sie die Verbesserung (berechnet durch den Ausdruck) und die mittlere Korrektklassifikationsrate (engl. accuracy) des optimierten dec_tree aus. Verwenden Sie eine Baumtiefe von 3 und einen random_state = 17 f\u00fcr die Reproduzierbarkeit. \n", "</ul>\n", "</div>\n"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 3.2.16:</b> Was sind die Vorteile des \"grid search\" - Verfahrens?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Einfluss der Skalierung\n", "\n", "Als letzten Schritt wollen wir den Einfluss unterschiedlicher Skalierungen auf unsere Trainingsdaten auswerten.\n", "\n", "##### Skalieren der Datens\u00e4tze mit Standard Scaler und MinMaxScaler\n", "\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.17:</b> \n", "\n", "Laden Sie die in sklearn.preprocessing enthaltenen Funktionen f\u00fcr den StandardScaler und den MinMaxScaler.\n", "\n", "</div>"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.18:</b> Bereiten Sie zwei verschiedene Datens\u00e4tze vor, einen skaliert mit StandardScaler und den anderen mit MinMaxScaler.\n", "<ul>\n", "<li> Erstellen Sie die entsprechenden Skalierer und verwenden Sie die Methode <code>.fit_transform()</code> unter Verwendung des gesamten Trainingsdatensatzes\n", "<li> Transformieren Sie dann den Testdatensatz mit den angepassten Skalern mithilfe der Funktion transform\n", "    \n", "</ul>\n", "</div>\n"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Evaluieren Sie die Leistung der skalierten Datens\u00e4tze\n", "\n", "\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 3.2.19:</b> Trainieren Sie nun ein weiteres Entscheidungsbaummodell mit jedem der neu skalierten Datens\u00e4tze (DecisionTreeClassifier, random_state = 17)\n", "<ul>\n", "<li> Berechnen Sie die Korrektklassifikationsrate des Testdatensatzes f\u00fcr beide Datens\u00e4tze\n", "<li> Verwenden Sie eine maximale Tiefe von 3 f\u00fcr den Trainingsprozess\n", "\n", "</ul>\n", "</div>\n", "\n"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["# Standard Scaler dataset\n", "# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["# MinMax Scaler dataset\n", "# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 3.2.20:</b> Vergleichen Sie die Korrektklassifikationsrate (engl. accuracy) der Ergebnisse beider Skalierungsoptionen mit der urspr\u00fcnglichen (ohne skalierte Datens\u00e4tze) Leistung bei einer Baumtiefe von drei. Was stellen Sie fest? Warum entspricht dieses Ergebnis nicht den Erwartungen? (Vergleichen Sie es nicht mit dem Ergebnis der Kreuzvalidierung) Empfehlen Sie, die Skalierung generell anzuwenden?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["### RandomForests mit scikit-learn\n", "\n", "Wir verwenden nicht nur einen Entscheidungsbaum, sondern mehrere. Dadurch ber\u00fccksichtigen wir Ausgaben mehrere Klassifikatoren als nur eine einzige (Ensemble-Methode - in diesem Fall Bagging). RandomForest-Klassifikatoren sind weniger anf\u00e4llig f\u00fcr Overfit."]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.model_selection import StratifiedKFold\n", "\n", "random_forest = RandomForestClassifier(random_state=17)\n", "fold = StratifiedKFold(n_splits=5, random_state=17, shuffle=True)\n", "\n", "scores = cross_val_score(random_forest, X_train, Y_train, cv=fold)\n", "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fast so gut wie unser optimierter Entscheidungsbaum und besser als unsere nicht optimierte Version, da nur die Standardwerte von RandomForestClassifiers verwendet und nicht optimiert werden. Sie sollten dieses Werkzeug des maschinellen Lernens im Hinterkopf behalten."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.2"}}, "nbformat": 4, "nbformat_minor": 4}