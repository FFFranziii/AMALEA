{"cells": [{"cell_type": "markdown", "source": ["# Oh sorry, das war ein Falsch-Positiv"], "metadata": {}}, {"cell_type": "markdown", "source": ["## Klassifizierungsmetriken\n", "Um zu verstehen, wie wir die Performanz eines Klassifikators messen k\u00f6nnen, werden wir zun\u00e4chst ein einfaches Zwei-Klassen-Problem betrachten und analysieren, wie es richtig oder falsch klassifiziert werden kann. Auf Grundlage dessen werden wir sp\u00e4ter in der Lage sein, weitere, spezifischere Metriken abzuleiten.\n", "\n", "Die Wahl der Metriken, die Sie f\u00fcr die Bewertung Ihrer maschinellen Lernalgorithmen verwenden, ist sehr wichtig, da sie beeinflusst, wie die Performanz gemessen und verglichen wird. Die ausgew\u00e4hlten Metriken beeinflussen somit, wie Sie die Wichtigkeit verschiedener Merkmale in den Ergebnissen gewichten und welchen Algorithmus Sie schlussendlich w\u00e4hlen. In diesem Abschnitt werden Sie erfahren, wie Sie in Python verschiedene Performanzmetriken des maschinellen Lernens mit scikit-learn ausw\u00e4hlen und verwenden k\u00f6nnen.\n", "\n", "Das ist wichtig, da Sie so in der Lage sind, Unterschiede zu erkennen und eine Auswahl zu treffen:\n", "- Unterschiedliche Transformationen der Daten, die zum Trainieren desselben maschinellen Lernmodells verwendet werden.\n", "- Unterschiedliche maschinelle Lernmodelle, die auf denselben Daten trainiert wurden.\n", "- Unterschiedliche Konfigurationen von maschinellen Lernmodellen, die auf denselben Daten trainiert wurde.  \n", "\n", "https://medium.com/greyatom/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["### Wahrheitsmatrix  (engl. Confusion Matrix)\n", "\n", "![FalsePositive-300x225.png](images/FalsePositive-300x225.png)\n", "\n", "\n", "Eine reale Bedingung kann entweder \"der Fall\" (positiv) oder \"nicht der Fall\" (negativ) sein. Unabh\u00e4ngig von den realen Bedingungen kann ein Klassifikator diese Bedingung basierend auf den Daten ebenfalls entweder als \"der Fall\" oder \"nicht der Fall\" klassifizieren. Daraus ergeben sich vier verschiedene Klassifikationsm\u00f6glichkeiten, die durch die Wahrheitsmatrix dargestellt werden.\n", "\n", "\n", "Zur Veranschaulichung wollen wir das Beispiel einer medizinischen Diagnose einer Herzerkrankung betrachten. Stellen Sie sich vor, wir verf\u00fcgen \u00fcber bereits vorhandene medizinische Daten sowie klinische Messungen und m\u00f6chten ein maschinelles Lernverfahren auf diese anwenden, um vorherzusagen, ob jemand eine Herzerkrankung entwickeln wird. Wie entscheiden wir, welches Modell am besten mit unseren Daten funktioniert?\n", "\n", "Die beiden Spalten in dieser Wahrheitsmatrix entsprechen dem, was der maschinelle Lernalgorithmus vorhergesagt hat, und die Zeilen entsprechen der Grundwahrheit.\n", "In diesem speziellen Fall handelt es sich um ein bin\u00e4res Klassifikationsproblem, da nur zwei Kategorien zur Auswahl stehen: _Herzkrankheit_ oder _hat keine Herzkrankheit._ Wahrheitsmatrizen k\u00f6nnen auch f\u00fcr mehr als zwei Kategorien verwendet werden.\n", "\n", "Jedes Mal, wenn ein neuer Patient klassifiziert wird, wird die Wahrheitsmatrix aktualisiert und ein weiteres Klassifizierungsergebnis wird zu einem der vier Felder hinzugef\u00fcgt. Wir werden diese Felder verwenden, um die H\u00e4ufigkeit jedes Klassifikationsergebnisses zu z\u00e4hlen.\n", "\n", "![confusion_matrix.png](images/confusion_matrix.png)\n", "\n", "\n", "\n", "Die obere linke Ecke enth\u00e4lt <font color=darkgreen>__richtig Positive__</font> (engl. true positives), das sind Patienten, die eine Herzerkrankung hatten und vom Algorithmus korrekt identifiziert wurden.  \n", "Die rechte untere Ecke enth\u00e4lt <font color=darkgreen>__richtig Negative__</font> (engl. true negatives), dies sind Patienten, die keine Herzerkrankung hatten und vom Algorithmus korrekt identifiziert wurden.  \n", "Die untere linke Ecke enth\u00e4lt <font color=darkred>__falsch Negative__</font> (engl. false negatives), dies sind Patienten, die eine Herzerkrankung haben, der Algorithmus dies aber nicht erkannte.  \n", "Die rechte obere Ecke enth\u00e4lt schlie\u00dflich <font color=darkred>__falsch Positive__</font> (engl. false positives), das sind Patienten, die keine Herzkrankheit haben, der Algorithmus dies aber dennoch behauptet.\n", "\n", "Diese Ged\u00e4chtnisst\u00fctze k\u00f6nnte n\u00fctzlich sein: Das erste Wort gibt an, ob die Vermutung richtig war oder nicht. Das zweite Wort gibt an, wie die Vorhersage lautete.\n", "\n", "Wir wollen so viele richtig-positive und so viele richtig-negative Vorhersagen wie m\u00f6glich haben, w\u00e4hrend wir gleichzeitig so wenig falsch-negative und falsch-positive Vorhersagen wie m\u00f6glich anstreben. Das ist eine Gratwanderung, denn wenn man den Klassifikator empfindlicher f\u00fcr Herzerkrankungen macht, f\u00fchrt das unweigerlich zu mehr falsch-positiven Vorhersagen, bei denen der Klassifikator eine Herzerkrankung \"erkennt\", wo eigentlich gar keine ist.\n", "\n", "\n", "\n", "Der Falsch-Positiv-Anteil/Fall-Out ist definiert als: \n", "\n", "$ \\frac{\\sum \\textrm{FP}}{\\sum \\textrm{FP+TN}} = 1 - \\frac{\\sum \\textrm{TN}}{\\sum \\textrm{FP+TN}} $\n", "\n", "Die zweite M\u00f6glichkeit, die auf der Spezifit\u00e4t basiert, ist f\u00fcr mehr als zwei Klassen oder Dimensionen der Matrix einfacher zu berechnen.\n", "\n", "\n", "Der _richtig-positiv-Anteil_ und der _falsch-positiv-Anteil_ sind Konzepte, die eng mit der ROC verwandt sind. Mehr dazu sp\u00e4ter."], "metadata": {}}, {"cell_type": "markdown", "source": ["Nachdem das Modell gelernt hat, Herzkrankheiten zu klassifizieren, testen wir es mit einem Datensatz mit echten Patientendaten. Die Diagnosen werden im Datensatzes als eine Liste von 0en (keine Herzerkrankung) und 1en (Herzerkrankung) dargestellt. Das bedeutet zum Beispiel, dass die ersten 4 Patienten in diesem Datensatz tats\u00e4chlich keine Herzerkrankung hatten, w\u00e4hrend die letzten 4 Patienten eine hatten.\n", "\n", "$$ground\\_truth \\ \\ = \\ \\ \\ [0,0,0,0,0,0,1,1,1,1,1]$$\n", "\n", "\n", "Wenn wir den Datensatz in das Modell einspeisen, erhalten wir diese Diagnosevorhersagen:\n", "\n", "$$Vorhersage \\ \\ \\ \\ \\ \\ = \\ \\ \\ [0,1,1,0,0,1,0,1,1,1]$$\n", "\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe/Frage 2.3.1:</b> F\u00fcllen Sie die folgende Wahrheitsmatrix aus, ersetzen Sie a, b, c und d durch die entsprechenden Anzahlen. Sie m\u00fcssen dazu den Code der Markdown-Zelle bearbeiten. \n", "</div>\n", "\n", "\n", "<table class=\"tg table-condensed table-bordered\">\n", "  <tr>\n", "    <th class=\"tg-c3ow\" colspan=\"2\" rowspan=\"2\"></th>\n", "    <th class=\"tg-7btt\" colspan=\"2\">Wahrer Zustand (Realit\u00e4t)</th>\n", "  </tr>\n", "  <tr>\n", "    <td class=\"tg-c3ow\">Herzkrankheit</td>\n", "    <td class=\"tg-c3ow\">Keine Herzkrankheit</td>\n", "  </tr>\n", "  <tr>\n", "      <td class=\"tg-7btt\" rowspan=\"2\"><b>Vorhergesagte Erkrankung</b></td>\n", "    <td class=\"tg-c3ow\">Herzerkrankung</td>\n", "    <td class=\"tg-c3ow\">a</td>\n", "    <td class=\"tg-c3ow\">b</td>\n", "  </tr>\n", "  <tr>\n", "    <td class=\"tg-c3ow\">Keine Herzerkrankung</td>\n", "    <td class=\"tg-c3ow\">c</td>\n", "    <td class=\"tg-c3ow\">d</td>\n", "  </tr>\n", "</table>\n", "\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "\n", "<b>Ihre Antwort:</b></div>", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe/Fragestellung 2.3.2:</b> Nun wollen wir das Gleiche wie zuvor tun. Statt eines bin\u00e4ren Klassifikationsproblem liegt diesmal ein Problem mit 3 verschiedenen Labels vor: Katze(Cat), Hund(Dog) und Affe(Mon). F\u00fcllen Sie die Tabelle aus.\n", "</div>\n", "\n", "$$actual =    \n", "[Dog, Mon, Mon, Mon, Cat]$$\n", "$$predicted =  \n", "[Cat, Dog, Mon, Mon, Mon]$$ \n", "\n", "<style type=\"text/css\">\n", ".tg  {border-collapse:collapse;border-spacing:0;}\n", ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n", ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n", ".tg .tg-baqh{text-align:center;vertical-align:top}\n", ".tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}\n", ".tg .tg-7btt{font-weight:bold;border-color:inherit;text-align:center;vertical-align:top}\n", "</style>\n", "<table class=\"tg table-condensed table-bordered\">\n", "  <tr>\n", "    <th class=\"tg-c3ow\" colspan=\"2\" rowspan=\"2\"></th>\n", "    <th class=\"tg-7btt\" colspan=\"3\">Wahrer Zustand (Realit\u00e4t)</th>\n", "  </tr>\n", "  <tr>\n", "    <td class=\"tg-c3ow\">Tats\u00e4chliche Katze</td>\n", "    <td class=\"tg-c3ow\">Tats\u00e4chlicher Hund</td>\n", "    <td class=\"tg-baqh\">Tats\u00e4chlicher Affe</td>\n", "  </tr>\n", "  <tr>\n", "    <td class=\"tg-7btt\" rowspan=\"3\">Vorhergesagte Bedingung</td>\n", "    <td class=\"tg-c3ow\">Vorhergesagte Katze</td>\n", "    <td class=\"tg-c3ow\">a</td>\n", "    <td class=\"tg-c3ow\">b</td>\n", "    <td class=\"tg-baqh\">c</td>\n", "  </tr>\n", "  <tr>\n", "    <td class=\"tg-c3ow\">Vorhergesagter Hund</td>\n", "    <td class=\"tg-c3ow\">d</td>\n", "    <td class=\"tg-c3ow\">e</td>\n", "    <td class=\"tg-baqh\">f</td>\n", "  </tr>\n", "  <tr>\n", "    <td class=\"tg-baqh\">Vorhergesagter Affe</td>\n", "    <td class=\"tg-baqh\">g</td>\n", "    <td class=\"tg-baqh\">h</td>\n", "    <td class=\"tg-baqh\">i</td>\n", "  </tr>\n", "</table>\n", "\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "\n", "<b>Ihre Antwort:</b></div>", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 2.3.3:</b> \n", "Best\u00e4tigen Sie Ihr Ergebnis mit der Confusion-Matrix Funktion von scikitlearn. Werfen Sie einen Blick in die <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\">Dokumentation</a> und wenden Sie diese Funktion auf die Daten der \u00dcbung 2.2.1.a an. Der Code sollte eine Matrix in der gleichen Form wie in der Tabelle oben ausgeben. Dazu ist am Ende ein kleiner zus\u00e4tzlicher Schritt notwendig, den Sie selbst herausfinden sollen.\n", "</div>"], "metadata": {}}, {"cell_type": "code", "execution_count": 1, "source": ["from sklearn.metrics import confusion_matrix\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 2.3.4:</b> Best\u00e4tigen Sie auch Ihre Ergebnisse zu \u00dcbung 2.2.1.b. (zweite Tabelle Katze, Hund, Affe)\n", "</div>"], "metadata": {}}, {"cell_type": "code", "execution_count": 2, "source": ["#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 2.3.5:</b> Berechnen Sie die Confusion-Matrix f\u00fcr den pima-indians-diabetes-Datensatz mit train_test_split, Testgr\u00f6\u00dfe 0,33, Seed 7 und logistischer Regression.\n", "Beachten Sie, dass die letzten Spalte des Datensatzes angibt, ob die Person Diabetes hat oder nicht.  \n", "1: positiv auf Diabetes getestet,  \n", "0: negativ auf Diabetes getestet\n", "<ul>\n", "<li>Hinweis: Sie k\u00f6nnen das LogisticRegression Modell verwenden, indem Sie die Methoden fit und predict verwenden. Schauen Sie sich dazu auch die Dokumentationen von sklearn an.\n", "</ul>\n", "</div>"], "metadata": {}}, {"cell_type": "code", "execution_count": 3, "source": ["# Cross Validation Classification Confusion Matrix\n", "from pandas import read_csv\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import confusion_matrix\n", "\n", "filename = 'data/pima-indians-diabetes.data.csv'\n", "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n", "dataframe = read_csv(filename, names=names)\n", "array = dataframe.values\n", "X = array[:,0:8]\n", "Y = array[:,8]\n", "\n", "test_size = 0.33\n", "seed = 7\n", "\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE\n", "\n", "print(\"Number of people with diabetes: \")\n", "print(\"Number of people without diabetes: \")\n", "\n", "\n", "print(\"True positives: \")\n", "print(\"True negatives: \") \n", "print(\"False positives: \")\n", "print(\"False negatives: \")\n"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["### Korrektklassifikationsrate (engl. accuracy)\n", "Ein einfacher Metrik, um einen Satz von Vorhersagen zu einem Klassifizierungsproblem zu bewerten, ist die Korrektklassifikationsrate.\n", "Siet ist das Verh\u00e4ltnis zwischen der Anzahl der richtigen Vorhersagen und der Anzahl aller getroffenen Vorhersagen. Normalerweise wird die Korrektklassifikationsrate als Prozentsatz zwischen 0 % f\u00fcr die schlechtestm\u00f6gliche Genauigkeit und 100 % f\u00fcr die bestm\u00f6gliche Genauigkeit angegeben.\n", "\n", "\n", "$$ \\textrm{Korrektklassifikationsrate} = \\frac{\\textrm{richtige Vorhersagen}}{\\textrm{alle Vorhersagen}} = \\frac{ \\color{darkgreen}{\\textrm{TP} + \\textrm{TN}}}{\\color{darkgreen}{\\textrm{TP} + \\textrm{TN}} +\\color{darkred}{\\textrm{FP} + \\textrm{FN}}}$$"], "metadata": {}}, {"cell_type": "markdown", "source": ["Angenommen, wir haben einen Datensatz mit Herzkrankheitsf\u00e4llen von Erwachsenen mittleren Alters. 10 % der Personen in diesem Datensatz haben eine Herzerkrankung, w\u00e4hrend 90 % keine haben. Nun trainieren wir einen sehr einfachen Klassifikator auf diesem Datensatz. Es stellt sich heraus, dass der Klassifikator eine genial einfache, aber dennoch genaue Strategie entwickelt hat: Er ignoriert die Daten, die Sie ihm geben, komplett und sagt einfach immer \"keine Herzerkrankung\" voraus.  "], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 2.3.6:</b> Welche Korrektklassifikationsrate hat dieser Klassifikator auf diesem Datensatz?\n", "</div>\n", "\n", "<div class=\"alert block alert-success\">\n", "\n", "<b>Ihre Antwort:</b></div>", ""], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 2.3.7:</b> Beschreiben Sie, wie der Datensatz aussehen muss, damit die Korrektklassifikationsrate eine potenziell n\u00fctzliche Metrik ist? (Eine vage Beschreibung ist ausreichend)\n", "</div>\n", "\n", "<div class=\"alert block alert-success\">\n", "\n", "<b>Ihre Antwort:</b></div>", ""], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert block alert-success\">\n", "<b>Aufgabe 2.3.8:</b> Implementieren Sie eine Funktion, die die Korrektklassifikationsrate  berechnet. Mit Ihrem bisherigen Kenntnisstand sollte Ihnen das leicht fallen.\n", "</div>"], "metadata": {}}, {"cell_type": "code", "execution_count": 4, "source": ["# Example of calculating classification accuracy\n", "# Calculate accuracy percentage between two lists\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE\n", "\n", "\n", "# Test accuracy\n", "true = [0,0,0,0,0,1,1,1,1,1]\n", "predicted = [0,1,0,0,0,1,0,1,1,1]\n", "accuracy = accuracy_metric(true, predicted)\n", "print(accuracy)"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 2.3.9:</b> Nun wollen wir die Korrektklassifikationsrate berechnen, aber mit Funktionen der Bibliothek sklearn und einem Datensatz. Parameter der Aufgabe sind:\n", "<ul>\n", "<li>Datensatz: pima-indians-diabetes\n", "<li> Resampling-Methode: k-fold, 10 Faltungen.\n", "<li> Modell: Logistische Regression, Solver: liblinear.\n", "<li> Hinweis: Die beiden folgenden Links k\u00f6nnten hilfreich sein:\n", "<UL>\n", "    <li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html</a>,\n", "     <li><a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values\">https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values</a>\n", "</ul>\n", "</div>"], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert alert-block alert-info\">\n", "\n", "<b>Hinweis:</b> Alle Scores werden so ausgegeben, dass sie in aufsteigender Reihenfolge sortiert werden k\u00f6nnen (der gr\u00f6\u00dfte Score ist der beste).  \n", "Einige Bewertungsmetriken (wie der mittlere quadratische Fehler oder der logarithmische Verlust) sind von Natur aus absteigende Scores (der kleinste Score ist der beste) und werden als solche von der Funktion cross validation.cross val score() negativ ausgegeben.  \n", "Das ist wichtig zu beachten, da einige Scores so negativ werden, die per Definition niemals negativ sein k\u00f6nnen.\n", "</div>"], "metadata": {}}, {"cell_type": "code", "execution_count": 5, "source": ["from pandas import read_csv\n", "from sklearn.model_selection import KFold, StratifiedKFold\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.linear_model import LogisticRegression\n", "\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["### Positiver Vorhersagewert, Sensitivit\u00e4t  (engl. precision, recall)\n", "\n", "Der __positive Vorhersagewert__ (engl. precision) kann als ein Ma\u00df daf\u00fcr gesehen werden, wie sehr Sie dem Klassifikator vertrauen k\u00f6nnen, wenn er \"positiv\" ausgibt. Wenn der Klassifikator einen deutlichen Hinweis ben\u00f6tigt, bevor er eine Herzerkrankung klassifiziert, gibt es eine geringe Anzahl von falsch-positiven Ergebnissen im Verh\u00e4ltnis zu den richtig-positiven Ergebnissen, was zu einem hohen positiven Vorhersagewert f\u00fchrt.\n", "\n", "Wenn ein sehr pr\u00e4ziser Klassifikator (mit einem hohen positiven Vorhersagewert) sagt, dass ein Patient eine Herzerkrankung hat, dann wird dies wahrscheinlich der Fall sein. Da der pr\u00e4zise Klassifikator jedoch einen starken Indikator ben\u00f6tigt, bleiben viele Patienten mit Herzerkrankungen unerkannt.\n", "\n", "$$ \\textrm{Positiver Vorhersagewert} = \\frac{\\textrm{richtig Positive}}{\\textrm{vorhergesagte Positive}} = \\frac{ \\color{darkgreen}{\\textrm{TP} }}{\\color{darkgreen}{\\textrm{TP}} +\\color{darkred}{\\textrm{FP}}}$$\n", "\n", "\n", "__Sensitivit\u00e4t__ oder Recall beschreibt, wie gut der Klassifikator im Erkennen von Positiven ist. Wenn der Klassifikator sehr d\u00fcnnh\u00e4utig ist und bereits auf winzige Unterschiede reagiert, wird er die meisten tats\u00e4chlichen Positiven in den Daten entdecken und nur sehr wenige falsch Negative \u00fcbrig lassen. Wenn ein sehr empfindlicher Klassifikator sagt, dass ein Patient eine Herzerkrankung hat, kann es sehr gut sein, dass dies nicht der Fall ist. Ein empfindlicher Klassifikator wird jedoch bei fast allen Patienten, die tats\u00e4chlich eine Herzerkrankung haben, eine solche erkennen. \n", "\n", "$$ \\textrm{Sensitivit\u00e4t} = \\frac{\\textrm{richtig Positive}}{\\textrm{tats\u00e4chlich Positive}} = \\frac{ \\color{darkgreen}{\\textrm{TP} }}{\\color{darkgreen}{\\textrm{TP}} +\\color{darkred}{\\textrm{FN}}}$$\n", "\n", "Daraus l\u00e4sst sich schlie\u00dfen, dass die Klassifizierung immer ein Balanceakt ist. "], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 2.3.10:</b> Angenommen, ein Screening auf Herzkrankheiten soll f\u00fcr eine breite Population junger und scheinbar gesunder Menschen entwickelt werden, um unbekannte F\u00e4lle von Herzkrankheiten aufzudecken. W\u00e4re ein guter Positiver Vorhersagewert oder eine gute Sensitivit\u00e4t wichtiger?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "\n", "<b>Ihre Antwort:</b></div>", ""], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 2.3.11:</b> Es ist gegeben, dass von 100 Personen 2 Personen eine Herzerkrankung haben (positiv). Welcher Positive Vorhersagewert und welche Sensitivit\u00e4t w\u00fcrden sich aus einem Klassifikator ergeben, der immer \"Herzkrankheit\" ausgibt?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "\n", "<b>Ihre Antwort:</b></div>", "", ""], "metadata": {}}, {"cell_type": "markdown", "source": ["![metrics.jpg](images/metrics.jpg)"], "metadata": {}}, {"cell_type": "markdown", "source": ["### Klassifikationsbericht (engl. Classification Report)\n", "\n", "Die scikit-learn Bibliothek bietet im Umgang mit Klassifizierungsproblemen einen komfortablen Bericht, der Ihnen einen schnellen \u00dcberblick \u00fcber die Genauigkeit eines Modells anhand einer Reihe von Ma\u00dfen gibt.  \n", "Die Funktion classification_report() berechnet f\u00fcr jede Klasse: \n", "- positiver Vorhersagewert (precision): $ \\frac{\\sum \\textrm{richtig Positive}}{\\sum \\textrm{vorhergesagte Positive}} $ <br><br>\n", "- Sensitivit\u00e4t (recall): $ \\frac{\\sum \\textrm{richtig Positive}}{\\sum \\textrm{tats\u00e4chlich Positive}} $ <br><br>\n", "- F1-Score: ist ein weiteres Ma\u00df f\u00fcr die Performanz eines Tests. Er ber\u00fccksichtigt sowohl den Positiven Vorhersagewert als auch die Sensitivit\u00e4t des Tests. Der F1-Score erreicht seinen besten Wert bei 1 (perfekter Positiver Vorhersagewert und Sensitivit\u00e4t) und den schlechtesten bei 0. <br><br>  \n", "- Support: Der Support z\u00e4hlt das Auftreten jeder Klasse in den gegebenen Daten. Im n\u00e4chsten Beispiel w\u00e4re z.B. 162 richtig Positive(141) + falsch Negative(21) und 92 richtig Negative(51) + falsch Positive(41).\n", "\n", "Das folgende Beispiel demonstriert den Bericht f\u00fcr ein bin\u00e4res Klassifizierungsproblem."], "metadata": {}}, {"cell_type": "code", "execution_count": 6, "source": ["# Cross Validation Classification Report\n", "from pandas import read_csv\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import classification_report\n", "\n", "filename = 'data/pima-indians-diabetes.data.csv'\n", "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n", "dataframe = read_csv(filename, names=names)\n", "array = dataframe.values\n", "X = array[:,0:8]\n", "Y = array[:,8]\n", "\n", "test_size = 0.33\n", "seed = 7\n", "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n", "model = LogisticRegression(solver = 'liblinear')\n", "model.fit(X_train, Y_train)\n", "predicted = model.predict(X_test)\n", "report = classification_report(Y_test, predicted)\n", "\n", "print(report)"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 2.3.12:</b> Was k\u00f6nnen Sie \u00fcber das Modell sagen? Ist es ein gutes Modell? Und warum?\n", "</div>\n", "\n", "<div class=\"alert block alert-success\">\n", "\n", "<b>Ihre Antwort:</b></div>", "", ""], "metadata": {}}, {"cell_type": "markdown", "source": ["### Logarithmischer Verlust\n", "\n", "Verlustfunktionen sind f\u00fcr Klassifikationsaufgaben genauso wichtig wie f\u00fcr die Regression. Obwohl die Wahrheitsmatrix (engl. Confusion Matrix) und die daraus abgeleiteten Metriken n\u00fctzliche Informationen \u00fcber die Performanz von Methoden des maschinellen Lernens liefern k\u00f6nnen, basieren sie auf diskreten Ereignissen und sind somit nicht kontinuierlich. Backpropagation-Algorithmen ben\u00f6tigen aber eine differenzierbare (und damit kontinuierliche) Funktion. \n", "\n", "F\u00fcr Klassifizierungsprobleme k\u00f6nnen wir die gleichen Algorithmen wie f\u00fcr Regressionsprobleme verwenden, wenn wir ihnen dazu einen zu minimierenden Verlust geben. Bei der Klassifikation ist die am meisten verwendete Verlustfunktion der logarithmische Verlust (oder logloss). Er bewertet die Vorhersagen der Wahrscheinlichkeiten der Klassenzugeh\u00f6rigkeit.  \n", "Die skalare Wahrscheinlichkeit zwischen 0 und 1 kann als ein Ma\u00df f\u00fcr das Vertrauen in eine Vorhersage eines Algorithmus verstanden werden. \n", "Ein kleinerer Logloss ist besser, wobei 0 einen perfekten Logloss darstellt.\n", "\n", "Zus\u00e4tzlich werden Vorhersagen, die nicht korrekt sind, in Abh\u00e4ngigkeit von der Sicherheit der Vorhersage bestraft. Wenn das Modell vorhersagt, dass das Eintreten einer Bedingung sehr unwahrscheinlich ist (vorhergesagte Wahrscheinlichkeit < 0,1), wird der Verlust sehr hoch, wenn die Bedingung tats\u00e4chlich eingetreten ist. (Siehe Abb. )\n", "\n", "\n", "![Imagen K-fold](images/Log_loss_graph.png)"], "metadata": {}}, {"cell_type": "markdown", "source": ["## Letzte Aufgabe:\n", "\n", "In dieser Aufgabe haben Sie ein Klassifikationsproblem, bei dem Sie entscheiden sollen, welches Modell Sie verwenden wollen. Gl\u00fccklicherweise hat bereits jemand Code geschrieben, der den bekannten Iris-Datensatz analysiert (https://en.wikipedia.org/wiki/Iris_flower_data_set). Die Analyse beinhaltet eine Datenvisualisierung und erstellt die folgenden sechs Modelle (auch hier gilt das \"No Free Lunch Theorem\"!)\n", "\n", "- Logistische Regression\n", "- Lineare Diskriminanzanalyse\n", "- k-nearest Neighbors\n", "- Entscheidungsbaum-Klassifikator\n", "- Gau\u00dfsche Naive Bayes\n", "- C-Support-Vektor-Klassifikation\n", "\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 2.3.13:</b> F\u00fchren Sie den Code aus und untersuchen Sie die Ausgabe\n", "</div>"], "metadata": {}}, {"cell_type": "code", "execution_count": 7, "source": ["# Load libraries\n", "from pandas import read_csv\n", "from pandas.plotting import scatter_matrix\n", "from matplotlib import pyplot\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.model_selection import KFold, StratifiedKFold\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.metrics import classification_report\n", "from sklearn.metrics import confusion_matrix\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.svm import SVC\n", "\n", "# Load dataset\n", "filename = 'data/iris.data.csv'\n", "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n", "dataset = read_csv(filename, names=names)\n", "\n", "# Summarize Data\n", "\n", "# Descriptive statistics\n", "# shape\n", "print(dataset.shape)\n", "# head\n", "print(dataset.head(20))\n", "# descriptions\n", "print(dataset.describe())\n", "# class distribution\n", "print(dataset.groupby('class').size())\n", "\n", "# Data visualizations\n", "\n", "# box and whisker plots\n", "dataset.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\n", "pyplot.show()\n", "# histograms\n", "dataset.hist()\n", "pyplot.show()\n", "# scatter plot matrix\n", "scatter_matrix(dataset)\n", "pyplot.show()\n", "\n", "# Prepare Data\n", "\n", "# Split-out validation dataset\n", "array = dataset.values\n", "X = array[:,0:4]\n", "Y = array[:,4]\n", "validation_size = 0.20\n", "seed = 7\n", "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed, shuffle=True)\n", "\n", "# Spot-Check Algorithms\n", "models = []\n", "models.append(('LR', LogisticRegression(solver = 'lbfgs', multi_class = 'multinomial', max_iter=200))) #These parameters are set to prevent warnings.\n", "models.append(('LDA', LinearDiscriminantAnalysis()))\n", "models.append(('KNN', KNeighborsClassifier()))\n", "models.append(('CART', DecisionTreeClassifier()))\n", "models.append(('NB', GaussianNB()))\n", "models.append(('SVM', SVC(gamma = 'auto'))) #Parameter set to prevent warnings.\n", "\n", "# evaluate each model in turn and prints Accuracy\n", "results = []\n", "names = []\n", "for name, model in models:\n", "\tkfold = StratifiedKFold(n_splits=10, random_state=seed, shuffle=True)\n", "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n", "\tresults.append(cv_results)\n", "\tnames.append(name)\n", "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "\tprint(msg) # Prints accuracy\n", "\n", "# Compare Algorithms\n", "fig = pyplot.figure()\n", "fig.suptitle('Algorithm Comparison')\n", "ax = fig.add_subplot(111)\n", "pyplot.boxplot(results)\n", "ax.set_xticklabels(names)\n", "pyplot.show()\n", "\n", "for name, model in models:\n", "    model.fit(X_train, Y_train)\n", "    predictions= model.predict(X_validation)\n", "    print(\"Model %s: Accuracy: %f \" % (name, accuracy_score(Y_validation, predictions)))\n", "    print(\"Model: \" + name)\n", "    print(confusion_matrix(Y_validation, predictions))\n", "    print(\"Classification Report: \" + name)\n", "    print(classification_report(Y_validation, predictions))"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 2.3.14:</b> Welchen Algorithmus w\u00fcrden sie w\u00e4hlen? Erkl\u00e4ren Sie Ihre Antwort! \n", "</div>\n", "\n", "<div class=\"alert block alert-success\">\n", "<b>Ihre Antwort:</b></div>", "", "", "", "", "", "", "", "", "", "", "", "", ""], "metadata": {}}, {"cell_type": "markdown", "source": ["## Literatur\n", "- https://medium.com/greyatom/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": [], "outputs": [], "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.3"}}, "nbformat": 4, "nbformat_minor": 4}