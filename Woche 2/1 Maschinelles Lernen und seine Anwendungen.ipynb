{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Maschinelles Lernen und seine Anwendungen\n", "\n", "### Einf\u00fchrung\n", "\n", "Wir beginnen diesen Abschnitt mit der Definition einiger Schl\u00fcsselbegriffe, die wir in dieser \u00dcbung verwenden werden.\n", "\n", "__Datensatz (engl. Dataset):__ Eine Sammlung von Daten wird als Datensatz bezeichnet. Im Allgemeinen ist sie wie eine Tabelle aufgebaut. Jede Zeile repr\u00e4sentiert ein Element, das mehrere Features haben kann. Jede Spalte repr\u00e4sentiert ein Feature.\n", "\n", "\n", "__Deskriptive Statistik:__ Sie ist der Vorl\u00e4ufer der _Pr\u00e4diktiven Statistik_ und basiert auf dem Gewinnen und Zusammenfassen von Informationen aus vergangenen Ereignissen. Zu den grundlegenden deskriptiven Analysetechniken geh\u00f6ren Anzahl, Summe, Durchschnittswert, Prozentsatz, Minimal- und Maximalwert sowie einfache Arithmetik (+, -, \u00d7 und \u00f7).  \n", "\n", "\n", "__Pr\u00e4diktive Statistik:__ Das Ergebnis einer Weiterentwicklung des Konzepts der _deskriptive Analytik_. Ihr Ziel ist es, basierend auf der Analyse historischer Daten, Vorhersagen \u00fcber die Zukunft oder \u00fcber unbekannte Ereignisse zu treffen. Um dies zu erreichen, werden bestimmte Modelle oder Algorithmen verwendet.\n", "\n", "![Imagen predictive analytics](images/predictive_analytics_in_a_pic.png)\n", "\n", "__Maschinelles Lernen:__ Ist ein Ansatz zum L\u00f6sen von Problemen der _Pr\u00e4diktiven Statistik_. Anstatt explizit definierte Regeln zur Verarbeitung von Daten anzuwenden, versucht maschinelles Lernen, die zugrunde liegenden allgemeinen Konzepte der Beziehungen im Datensatz herauszufinden. Diese Methoden sind in der Lage, die traditionelle regelbasierte Programmierung bei vielen Aufgaben weit zu \u00fcbertreffen, haben aber auch ihre eigenen Komplikationen und Nachteile, die sorgf\u00e4ltig abgewogen werden m\u00fcssen.\n", "\n", "\n", "In dieser \u00dcbung werden Sie lernen, Ans\u00e4tze des maschinellen Lernens anzuwenden, um fundierte (aus Trainingsdaten gelernte) Vermutungen f\u00fcr die Vorhersage aufzustellen.\n", "\n", "Beim maschinellen Lernen lernt ein _Pr\u00e4diktionsmodell_ seine Parameter aus Trainingsdaten. Damit ist das System in der Lage, Vorhersagen aus Eingabedaten zu erstellen. Ein besonderes Merkmal vieler Algorithmen des maschinellen Lernens ist die F\u00e4higkeit, Informationen aus den Trainingsdaten interpolieren und extrapolieren zu k\u00f6nnen. Es gibt jedoch einige Einschr\u00e4nkungen bei der Generalisierung. Zudem wird das Modell wahrscheinlich am besten mit Daten funktionieren, die den Trainingsdaten \u00e4hnlich sind. Daher werden wir unsere Daten meistens in Trainings-, Test- und Validierungsdaten aufteilen. Diese drei Konzepte sind f\u00fcr fast alle Aufgaben des maschinellen Lernens wichtig und werden im Folgenden definiert:\n", "\n", "\n", "- Trainingsdaten: Die Daten und Beispiele, die f\u00fcr die Optimierung der Parameter des Modells verwendet werden. \n", "- Testdaten: Normalerweise wollen wir wissen, wie gut der maschinelle Lernalgorithmus mit Daten umgeht, die er zuvor noch nicht gesehen hat. Dadurch k\u00f6nnen wir absch\u00e4tzen, wie gut der Algorithmus in der realen Welt funktionieren w\u00fcrde. Diese Leistungsma\u00dfe evaluieren wir daher mit einem Testdatensatz, der von den Daten getrennt ist, die f\u00fcr das Training des maschinellen Lernsystems verwendet wurden. (Legen Sie diese Daten beseite und evaluieren Sie nur einmal am Ende Ihrer Optimierung! Sie sollten nicht mit Testdaten trainieren...)\n", "- Validierungsdaten: Der Validierungssatz wird verwendet, um den Generalisierungsfehler w\u00e4hrend oder nach dem Training zu sch\u00e4tzen, sodass die Hyperparameter (z. B. Lernrate, k, Baumtiefe, Batch-Gr\u00f6\u00dfe, ...) unabh\u00e4ngig von Test- und Trainingsdaten aktualisiert werden k\u00f6nnen. Daher ist es wichtig, die Validierungsdaten von Test- und Trainingsdaten zu trennen. Typischerweise verwendet man etwa 80 % der Trainingsdaten f\u00fcr das Training und 20 % f\u00fcr die Validierung.\n", "\n", "<!--- www.digitalistmag.com/digital-economy/2018/03/15/differences-between-machine-learning-predictive-analytics-05977121 -->\n", "\n", "Das Ziel der _Pr\u00e4diktiven Modellierung_ ist es, Modelle zu erstellen, die gute Vorhersage treffen. Dies wird erreicht, indem das Modell mithilfe der Trainingsdaten trainiert wird. Die Performanz des Modells wird anschlie\u00dfend mit den Testdaten bestimmt. F\u00fcr das Optimieren der Hyperparameter werden die Validierungsdaten verwendet. __In dieser \u00dcbung werden jedoch keine Hyperparameter optimiert.__ Dementsprechend wird kein Validierungssatz ben\u00f6tigt und alle Daten werden f\u00fcr Training und Test verwendet. Sie werden verschiedene Methoden kennenlernen, um Ihre Daten in Trainings- und Tests\u00e4tze zu unterteilen.\n", "Zudem werden Sie lernen, wie sie diese Daten verwenden k\u00f6nnen, um ein maschinelles Lernmodell zu trainieren.\n", "\n", "Es gibt mehrere Algorithmen/Netzwerke, die als Vorhersagemodelle verwendet werden k\u00f6nnen, prominente Beispiele sind:\n", "- K-Nearest Neighbor Algorithmen\n", "- Neuronale Netze (Multi Layer Perceptrons MLPs)\n", "- Convolutional Neural Networks (CNNs)\n", "- Recurrent Neural Networks (RNNs)\n", "- Und viele weitere\n", "\n", "\n", "![xkcd.png](images/xkcd.png)\n", "\n", "### Anwendungen\n", "\n", "\n", "### Regressionsprobleme\n", "Im Falle von Regressionsproblemen muss ein maschinelles Lernmodell eine _Gr\u00f6\u00dfe_ (kontinuierlicher Wert) auf Basis von neuen Daten vorhersagen. In der Praxis funktioniert das, indem eine Funktion auf einen bekannten Satz von Datenpunkten angepasst wird. Die Vorhersage des Modells ist nichts anderes als die Ausgabe der Funktion mit der neuen Eingabe.\n", "\n", "H\u00e4ufig verwendete Regressionsmethoden sind die _lineare Regression_ und die _logistische Regression_.\n", "Lineare Funktionen sind einfach anzupassen und zu verstehen. Allerdings kann die Genauigkeit gering ausfallen, wenn die den Daten zugrunde liegende Beziehung nichtlinear ist. Die logistische Regression passt eine logistische Sigmoidkurve an die gegebenen Daten an. Diese wird normalerweise verwendet, um eine Wahrscheinlichkeitsfunktion zu approximieren, die sp\u00e4ter als Grundlage f\u00fcr eine Klassifizierungsentscheidung verwendet werden kann.\n", "\n", "\n", "![linear_logistic_regression](images/linear_logistic_regression.jpeg)\n", "\n", "\n", "### Klassifizierungsprobleme\n", "Bei Klassifizierungsproblemen versucht das Modell, eine diskrete Klasse oder Kategorie von neuen Daten vorherzusagen. \n", "Um ein Klassifizierungsproblem zu l\u00f6sen, kann man grunds\u00e4tzlich auch zun\u00e4chst ein Regressionsmodell erstellen. F\u00fcr die Klassifizierung werden jedoch andere Metriken und Modellfunktionen (z. B. logistisch) gew\u00e4hlt. Zus\u00e4tzlich werden Schwellenwerte f\u00fcr die Klassifikation auf die Modellvorhersage angewendet, um eine diskrete Ausgabe zu erzeugen.\n", "\n", "![regression_classification_weather_example](images/regression_classification_weather_example.jpeg)\n", "<p style=\"text-align: center;\">\n", "    Abb. 1 - Regression und Klassifizierung auf Basis der Wettervorhersage\n", "</p>\n", "\n", "\n", "\n", "Sowohl Regressions- als auch Klassifikationsprobleme k\u00f6nnen mit Methoden des _\u00fcberwachten Lernens_ gel\u00f6st werden.  Bei diesem Ansatz m\u00fcssen sowohl die Eingabe als auch die entsprechende L\u00f6sung (Label) im Voraus bekannt sein. Eingaben und Labels werden dann dem Algorithmus \u00fcbergeben. Dieser versucht dann, eine allgemeine, konzeptionelle Beziehung zwischen Eingaben und L\u00f6sungen zu lernen, bis er schlie\u00dflich in der Lage ist, eine sinnvolle Ausgabe f\u00fcr neue Eingaben zu liefern.\n", "\n", "### Clustering-Probleme\n", "Un\u00fcberwachte Lernmethoden wie Clustering ben\u00f6tigen keine L\u00f6sungsmenge, um zu funktionieren. Wir werden uns hier nicht auf ihre Leistungsmetriken konzentrieren, da dies tiefergehendes Wissen erfordert. Sie werden mehr \u00fcber Clustering in Woche 3 erfahren.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Aufteilen von Datens\u00e4tzen in Trainings- und Tests\u00e4tze\n", "\n", "Wenn Sie mit einem Modell arbeiten und es trainieren wollen, verf\u00fcgen Sie bereits \u00fcber einen Datensatz. Um das Modell nach dem Training zu testen, ben\u00f6tigen Sie neue Daten, die noch nicht im Trainingssatz aufgetreten sind. Vor allem in fr\u00fchen Entwicklungsphasen kann es allerdings sein, dass Ihnen dazu keine gro\u00dfe Menge an Daten zur Verf\u00fcgung steht.\n", "\n", "In solchen Situationen ist die naheliegendste L\u00f6sung, den vorhandenen Datensatz in zwei Gruppen zu unterteilen, eine zum Trainieren und eine zum Testen. Diese Unterteilung f\u00fchren Sie noch vor Beginn des Trainings durch. Ein Teil wird zum Trainieren des Modells verwendet. Sobald die Maschine trainiert ist, werden wir die Vorhersagen mit den Testdaten vergleichen, um die Leistung des Modells abzusch\u00e4tzen.\n", "\n", "Die Gr\u00f6\u00dfe der Aufteilung kann von der Gr\u00f6\u00dfe und den Eigenschaften des Datensatzes abh\u00e4ngen. Allerdings ist es \u00fcblich, 67 % der Daten zum Trainieren und die restlichen 33 % zum Testen zu verwenden. Ein Split-Verh\u00e4ltnis von 80/20 ist ebenfalls sehr \u00fcblich. \n", "\n", "Diese Auswertungstechnik des Algorithmus ist sehr schnell. Sie ist ideal f\u00fcr gro\u00dfe Datens\u00e4tze (Millionen von Eintr\u00e4gen), bei denen es starke Hinweise darauf gibt, dass beide Aufteilungen (engl. splits) der Daten das zugrunde liegende Problem repr\u00e4sentieren. Wegen der Geschwindigkeit ist es sinnvoll, diesen Ansatz zu verwenden, wenn der zu untersuchende Algorithmus langsam beim Training oder bei der Inferenz ist. \n", "Ein Nachteil dieser Technik ist, dass sie eine hohe Varianz haben kann. Das bedeutet, dass Unterschiede im Trainings- und Testdatensatz zu bedeutenden Unterschieden in der Sch\u00e4tzung der Genauigkeit f\u00fchren k\u00f6nnen.\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 2.1.1:</b> F\u00fchren Sie den folgenden Codeblock aus und spielen Sie mit den Kontrollk\u00e4stchen. Nutzen Sie Ihre gewonnenen Erkenntnisse, um die folgenden Aufgaben zu l\u00f6sen.\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Nun sind Sie dran:</b> F\u00fchren Sie den Code im n\u00e4chsten Codeblock aus. Der Code f\u00fchrt eine lineare Regression f\u00fcr einen beispielhaften Diabetes-Datensatz durch. Weitere Informationen zu diesem Datensatz finden Sie unter: \n", "<a href=\"https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\">https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html</a>    \n", " oder im ganzen Paper <a href=\"http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf\">http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf</a> (seien Sie gewarnt, es sind etwa 44 Seiten. Es ist nicht empfehlenswert, alles zu lesen). Au\u00dferdem erzeugt der Code ein interaktives Diagramm, um Ihnen bei der L\u00f6sung der ersten Aufgabe zu helfen.\n", "</div>"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# Code source: Jaques Grobler\n", "# License: BSD 3 clause\n", "\n", "# https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n", "\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "from sklearn import datasets, linear_model\n", "from sklearn.metrics import mean_squared_error, r2_score\n", "\n", "from ipywidgets import interact, interactive, fixed, interact_manual\n", "\n", "# Load the diabetes dataset\n", "diabetes = datasets.load_diabetes()\n", "\n", "# Use only one feature\n", "diabetes_X = diabetes.data[:, np.newaxis, 2]\n", "\n", "# Split the data into training/testing sets\n", "diabetes_X_train = diabetes_X[:-20]\n", "diabetes_X_test = diabetes_X[-20:]\n", "\n", "# Split the targets into training/testing sets\n", "diabetes_y_train = diabetes.target[:-20]\n", "diabetes_y_test = diabetes.target[-20:]\n", "\n", "# Create linear regression object\n", "regr = linear_model.LinearRegression()\n", "\n", "# Train the model using the training sets\n", "regr.fit(diabetes_X_train, diabetes_y_train)\n", "\n", "# Make predictions using the testing set\n", "diabetes_y_pred = regr.predict(diabetes_X_test)\n", "\n", "# The coefficients\n", "print('Coefficients: \\n', regr.coef_)\n", "\n", "def f(p1: bool, p2: bool, p3: bool, p4: bool):\n", "    plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n", "\n", "    # Plot outputs\n", "    if p1 == True:\n", "        plt.scatter(diabetes_X_train, diabetes_y_train,  color='black')\n", "    #plt.scatter(diabetes_X_train, diabetes_y_pred, color='blue')\n", "    \n", "    if p2 == True:\n", "        plt.scatter(diabetes_X_test, diabetes_y_test,  color='green')\n", "\n", "    if p3 == True:\n", "        plt.scatter(diabetes_X_test, diabetes_y_pred, color='blue')\n", "\n", "    if p4 == True:\n", "        plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=1)\n", "    \n", "    plt.xlim(-0.10997004779892904, 0.19024997788107048)\n", "    plt.ylim(8.940894039735102, 362.05910596026484)\n", "    \n", "    # this hides the numbers on the axis\n", "    #plt.xticks(())\n", "    #plt.yticks(())\n", "\n", "    plt.show()\n", "    \n", "interactive_plot = interactive(f, p1=True, p2=True, p3=True, p4=True)\n", "output = interactive_plot.children[-1]\n", "output.layout.height = '400px'\n", "interactive_plot\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe/Frage 2.1.2:</b> Vervollst\u00e4ndigen Sie den folgenden Text, sodass er mit Hilfe der Tabelle unten und der interaktiven Grafik widerspruchsfrei ist, und vervollst\u00e4ndigen Sie dann die Tabelle.\n", "\n", "    \n", "    \n", "Der folgende Text beschreibt die Schritte zum Erstellen eines Vorhersagemodells f\u00fcr eine lineare Regression: <br>\n", "<br>\n", "Indem Sie ??? und ??? betrachten, k\u00f6nnen Sie einen Blick auf den gesamten Datensatz werfen.  Im obigen Diagramm wird die Aufteilung der Daten durch unterschiedliche Farben dargestellt. Typischerweise wird der Datensatz in Train, Test und Validierung unterteilt, aber f\u00fcr einfache Modelle kann auch eine einfache Test-Train-Aufteilung verwendet werden. In der Regel ist der Trainingssatz (80 %) gr\u00f6\u00dfer als der Testsatz (20 %).\n", "Nach der Aufteilung wird der Trainingssatz an das lineare Regressionsmodell \u00fcbergeben, das \u00fcber einen Parameter verf\u00fcgt, der eine lineare Funktion erzeugt. Sie k\u00f6nnen diese Funktion einblenden, indem Sie auf ??? klicken.<br>\n", "<br>\n", "Mithilfe dieser Linie k\u00f6nnen wir dann die Werte von y f\u00fcr die Werte x des Testsatzes berechnen. Diese Punkte werden durch ??? dargestellt.  \n", "<br>\n", "Offensichtlich werden alle diese Punkte auf der Linie liegen. In einem n\u00e4chsten Schritt k\u00f6nnen verschiedene Metriken berechnet werden, die uns eine Vorstellung davon geben, wie gut dieses Modell mit diesen Daten funktioniert. Mit diesen Metriken w\u00fcrden wir das Modell mit anderen Modellen oder mit anderen Parametern f\u00fcr dieses Modell vergleichen.  \n", "<br>\n", "Wenn wir mit der Auswahl des Modells und seiner Parameter fertig sind, werden wir das Modell erneut trainieren, dieses Mal mit der kompletten Datenbank. \n", "</div>\n", "\n", "|         -          |        -                     |\n", "|--------------------|------------------------------|\n", "| Trainingssatz      | ???                     |\n", "|--------------------|------------------------------|\n", "| Testsatz           | ???                    |\n", "|--------------------|------------------------------|\n", "| Vorhergesagter Datensatz  | ???                    |\n", "|--------------------|------------------------------|\n", "| Regressionsfunktion | ???                    |\n", "\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 2.1.3:</b> Jetzt ist es an der Zeit, Ihre eigene Train-Split Funktion zu schreiben. Verwenden Sie die folgenden Anweisungen und die gegebene Codevorlage.\n", "<ul>\n", "<li> Die Funktion erh\u00e4lt den Originaldatensatz und gibt die beiden Partitionen/Variablen (genannt train und test) zur\u00fcck.\n", "<li> Au\u00dferdem erh\u00e4lt die Funktion eine Zahl zwischen 0 und 1, die das prozentuale Gr\u00f6\u00dfenverh\u00e4ltnis zwischen \"train\" und \"test\" darstellt. Das hei\u00dft, wenn z. B. split = 0,7 ist, werden 70 % der Daten f\u00fcr das Training verwendet und die restlichen 30 % sind f\u00fcr das Testen reserviert.\n", "<li> Wir wollen, dass die Aufteilung zuf\u00e4llig ist, also m\u00fcssen Sie wahrscheinlich aus dem Modul <i>\"random.py\"</i> (das Teil der <i>Python-Standardbibliothek</i> ist) die Funktionen <i>seed</i> und <i>randrange</i> importieren. Die <i>seed</i> Funktion sorgt daf\u00fcr, dass das Ergebnis von <i>randrange</i> bei jeder Codeausf\u00fchrung das gleiche ist.\n", "<li>Eine gute Vorgehensweise w\u00e4re es, eine Kopie des Originaldatensatzes innerhalb der Funktion zu erstellen. Auf diese Weise wird der Originaldatensatz nicht ver\u00e4ndert. Nehmen Sie dann einige Zeilen dieses Datensatzes und f\u00fcgen Sie diese in eine andere Liste ein. Geben sie beide Listen zur\u00fcck. Sie k\u00f6nnen selbst entscheiden k\u00f6nnen, was train und was test ist.\n", "</ul>\n", "</div>"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Example of Splitting a Contrived Dataset into Train and Test\n", "from random import seed\n", "from random import randrange\n", "\n", "# Split a dataset into a train and test set\n", "def my_train_test_split(dataset: list, split: float):\n", "    #STUDENT CODE HERE\n", "\n", "    #STUDENT CODE until HERE\n", "    return train, test"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 2.1.4:</b> Testen Sie Ihre train_test_split Funktion anhand des folgenden Beispiels: \n", "</div>"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# test train/test split\n", "seed(1)\n", "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]  # Dataset is 1 indexed.\n", "train, test = my_train_test_split(dataset,0.7)\n", "print(train)\n", "print(test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Es gibt viele Methoden, um die Aufteilung des Datensatzes (in Trainings- und Test-S\u00e4tze) und die Auswertung des Modells, \u00fcber die wir gerade gesprochen haben, durchzuf\u00fchren.\n", "In diesem Abschnitt lernen wir die zwei Hauptmethoden kennen, diese w\u00e4ren:\n", "- Aufteilen, Trainieren und Testen\n", "- k-fache Kreuzvalidierung (engl. k-fold cross validation)\n", "\n", "Neben diesen gibt es noch weitere Methoden, die oben vorgestellten Methoden bilden aber die Grundlagen.  \n", "Beiden Verfahren geh\u00f6ren zu den sogenannten __Resampling-Methoden__, also statistischen Methoden, die es erm\u00f6glichen, die Leistung des Modells zu __sch\u00e4tzen__, d. h. wie gut es funktionieren wird und wie gut seine Vorhersagen sein werden.\n", "Das Ziel von Resampling-Methoden ist es, die Trainingsdaten bestm\u00f6glich zu nutzen, um die Leistung eines Modells auf neuen, zuvor ungesehenen Daten m\u00f6glichst genau zu sch\u00e4tzen.  \n", "\n", "Sobald wir eine genaue Sch\u00e4tzung der Performanz des Modells erreicht haben, k\u00f6nnen wir diese verwenden, um zu entscheiden, welchen Satz von Modellparametern wir verwenden oder welches Modell wir ausw\u00e4hlen.  \n", "Sobald wir ein Modell ausgew\u00e4hlt haben, k\u00f6nnen wir das endg\u00fcltige Modell mit dem gesamten Trainingsdatensatz trainieren und damit beginnen, Vorhersagen zu treffen.  \n", "Am Ende dieses Abschnitts erfahren Sie, wann Sie welche Resampling-Methode verwenden sollten.\n", "\n", "Ein gemeinsames Merkmal aller Resampling-Methoden ist die Notwendigkeit, die Zeilen f\u00fcr den Trainings-, Test- und Validierungsdatensatz zuf\u00e4llig auszuw\u00e4hlen.\n", "Damit soll sichergestellt werden, dass das Training und die Evaluierung eines Modells objektiv sind.  \n", "Wenn mehrere Algorithmen oder mehrere __Konfigurationen__ desselben Algorithmus verglichen werden, sollte der exakt gleiche Train- und Test-Split des Datensatzes verwendet werden (Reproduzierbarkeit). Dadurch wird sichergestellt, dass der Vergleich der Performanz konsistent ist und wir \u00c4pfel mit \u00c4pfeln vergleichen. Dies kann erreicht werden, indem der __random seed__ des Zufallszahlengenerators vor der Aufteilung der Daten auf die gleiche Weise festgelegt wird, oder indem dieselbe Aufteilung des Datensatzes auf alle Algorithmen angewandt wird.  "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u00dcbung:\n", "Nachdem Sie erfolgreich Ihre erste train/split Funktion geschrieben haben, d\u00fcrfen Sie nun endlich die train/split-Funktion verwenden, die von der Scikit-Learn-Bibliothek bereitgestellt wird. Scikit-Learn sklearn ist eine h\u00e4ufig verwendete Bibliothek, die Ihre Produktivit\u00e4t booooooostet. \n", "Es handelt sich hierbei um eine freie Software-Bibliothek f\u00fcr maschinelles Lernen in der Programmiersprache Python. Sie bietet verschiedene Klassifizierungs-, Regressions- und Clustering-Algorithmen, einschlie\u00dflich Support-Vektor-Maschinen, Random Forests, Gradient Boosting, k-means und DBSCAN, und ist so konzipiert, dass sie mit den numerischen und wissenschaftlichen Python-Bibliotheken NumPy und SciPy zusammenarbeitet.\n", "\n", "Eine Auswahl von Funktionen finden Sie in dem [Scikit-Learn Cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Scikit_Learn_Cheat_Sheet_Python.pdf) (entnommen von https://www.datacamp.com/community/blog/scikit-learn-cheat-sheet). Beantworten Sie die folgende Frage, nachdem Sie das Cheatsheet durchgelesen haben: "]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 2.1.5:</b> Welche Funktion w\u00fcrden Sie zum Aufteilen des Datensatzes w\u00e4hlen? Welche Bibliothek w\u00fcrden Sie importieren?\n", "</div>\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 2.1.6:</b> Welche Eingangsparameter hat die Funktion und was ist ihr R\u00fcckgabewert?\n", "</div>\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", "", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Nun ist es an der Zeit, die Funktion zu verwenden. Zuerst werden wir die Funktion auf einen k\u00fcnstlichen Datensatz anwenden (nur die Zahlen von 1 bis 10).\n", "Die Gr\u00f6\u00dfe des Testsatzes soll 20 % betragen."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 2.1.7:</b> Schreiben und testen Sie Ihre L\u00f6sung im folgenden Codeblock.\n", "</div>"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# Example of Splitting a Contrived Dataset into Train and Test\n", "from random import seed\n", "from random import randrange\n", "\n", "# test train/test split\n", "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n", "\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE\n", "\n", "print(train)\n", "print(test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u00dcbung: Pima-Indianer Diabetes-Datensatz\n", "Der Datensatz ist im KI-Campus verf\u00fcgbar. Das urspr\u00fcngliche Paper, das diesen Datensatz verwendet, finden Sie hier: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245318/\n", "In dieser Arbeit aus dem Jahr 1984 wurde ein Neuronales Netzwerkmodell f\u00fcr das Auftreten von Diabetes mellitus in einer Hochrisikopopulation von Pima-Indianern erstellt, mit einer Sensitivit\u00e4t und Spezifit\u00e4t von 76 %.\n", "\n", "__Datensatzinformationen:__\n", "\n", "Bei der Auswahl dieser F\u00e4lle aus einer gr\u00f6\u00dferen Datenbank wurden mehrere Einschr\u00e4nkungen gemacht. Insbesondere sind alle Patienten hier weiblich, mindestens 21 Jahre alt und stammen von Pima-Indianern ab.\n", "\n", "Informationen zu den Features:\n", "\n", "1. Anzahl der Schwangerschaften\n", "2. Plasmaglukosekonzentration a 2 Stunden in einem oralen Glukosetoleranztest\n", "3. Diastolischer Blutdruck (mm Hg)\n", "4. Trizeps-Hautfaltendicke (mm)\n", "5. 2-Stunden-Serum-Insulin (mu U/ml)\n", "6. Body-Mass-Index (Gewicht in kg/(Gr\u00f6\u00dfe in m)^2)\n", "7. Diabetes-Stammbaumfunktion\n", "8. Alter (Jahre)\n", "9. Klassenvariable (0 oder 1)\n", "\n", "Nun, da Sie die Features des Datensatzes kennen, k\u00f6nnen wir mit der Codierung beginnen. \n", "\n", "<div class=\"alert block alert-warning\">\n", "<b>L\u00f6sen Sie die Teilaufgaben 1-3 in den entsprechenden nachfolgenden Codebl\u00f6cken</b> \n", "<ul>\n", "  <li>Importieren Sie die CSV-Datei mit dem Datensatz der Pima-Indianer (verwenden Sie Abk\u00fcrzungen f\u00fcr die Attribute)</li>\n", "  <li>Wie viele Indianer haben keinen Diabetes (Klasse = 0) oder haben Diabetes (Klasse = 1)? Wie ist der Anteil/das Verh\u00e4ltnis dieser beiden Gr\u00f6\u00dfen?</li>\n", "  <li>F\u00fchren Sie einen Datensatzsplit mit der Methode train_test_split von sklearn mit einer Testgr\u00f6\u00dfe von 0,25<br> (bzw. einer train-Gr\u00f6\u00dfe von 0,75) und einem random_state = 0 durch?</li>\n", "</ul>\n", "</div>\n"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# loading Libraries\n", "from pandas import read_csv\n", "import pandas as pd\n", "import numpy as np\n", "\n", "#SUBTASK 1: Load the pima-indians-diabetes dataset\n", "\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["#SUBTASK 2:\n", "\n", "#How many Indians have diabetes (class =1) or have no diabetes (class = 0)? \n", "#What is the proportion of these two quantities?\n", "#Hint: the easiest way is to use the groupby method in combination of the size method\n", "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html\n", "\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE\n", "\n", "print(\"Number of Indians without diabets: \")\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE\n", "\n", "print(\"Number of Indians with diabets: \")\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE\n", "\n", "print(\"Ratio of Indians with diabetes over those without diabetes: \")\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE\n"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["#SUBTASK 3: \n", "\n", "#Divide the dataset into training and testing data using the train_test_split function\n", "\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE\n", "\n", "print(\"Number of elements in the testset: \")\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE\n", "\n", "print(\"Number of elements in the trainingset: \")\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Bonusfrage:</b> Welche indische Frau (ID) hatte den dicksten Arm?\n", "</div>"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 2.1.8:</b> Was w\u00e4re der Nachteil, wenn die Verteilung der Klassen (in unserem Datensatz Klasse 0/1) im Trainingsdatensatz anders w\u00e4re als im Testdatensatz? Zum Beispiel, wenn die Klasse 1 80 % des Trainingsdatensatzes ausmacht, aber nur 20 % im Testdatensatz.\n", "\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", "", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Kreuz-Validierung (engl. Cross-Validation)\n", "\n", "Kreuzvalidierungsverfahren lassen sich einteilen in:\n", "- __ersch\u00f6pfend:__ Daten werden in Trainings- und Validierungss\u00e4tze aufgeteilt. Es werden alle M\u00f6glichkeiten zur Aufteilung der Daten erprobt.  Zu dieser Gruppe geh\u00f6ren:\n", "    - Leave One Out Cross-Validation (ein Spezialfall der \"Leave-p-out cross-validation\")\n", "\n", "- __nicht-ersch\u00f6pfend:__ Die Methode berechnet nicht alle m\u00f6glichen Wege der Aufteilung der Daten.  Bekannte Beispiele sind: \n", "    - k-fache Kreuzvalidierung\n", "    - Wiederholte zuf\u00e4llige Test-Train-Splits\n", "    - Holdout-Methode\n", "    \n", "### k-fache Kreuzvalidierung (engl. k-fold Cross-Validation)\n", "Die __k-fold Cross-Validation__ (k-fold CV) - Methode ist eine Resampling-Methode, die eine genauere Sch\u00e4tzung der Algorithmus-Performanz liefert, also mit einer geringeren Varianz als eine einfache Training-Test-Satz-Aufteilung.  \n", "\n", "Hierbei wird der Datensatz zun\u00e4chst in k Gruppen aufgeteilt. Jede Gruppe von Daten wird als Fold bezeichnet, daher der Name k-fold cross-validation.\n", "\n", "In der folgenden Abbildung sehen Sie, dass jede Zeile einen Fold und jede Spalte eine Trainings- und Testiteration darstellt. Zum Beispiel wird in der ersten Iteration (Modell 1) die Fold 1 die Testfalte sein und die anderen die Trainingsfalten.\n", "![Imagen K-fold](images/K-fold_cross_validation_EN.jpg)\n", "\n", "Der Algorithmus wird dann k-mal trainiert und evaluiert. Die Performanz wird anschlie\u00dfend zusammengefasst, indem der Mittelwert der Performanz aller Evaluierungen gebildet wird. \n", "\n", "Der Algorithmus wird auf k - 1 Folds der Daten trainiert und dann auf der k-ten zur\u00fcckgehaltenen Fold getestet. \n", "Dies wird wiederholt, so dass jede der k Folds des Datensatzes eine Chance erh\u00e4lt, zur\u00fcckgehalten und als Testsatz verwendet zu werden. Beachten Sie aber, dass dabei auch k getrennte Modelle trainiert werden, sodass ein Testsatz nie f\u00fcr das Training eines Modells verwendet wird.\n", "\n", "Daher sollte die Anzahl der Zeilen in Ihrem Trainingsdatensatz durch k teilbar sein, um sicherzustellen, dass jede der k Gruppen die gleiche Anzahl von Zeilen hat.  \n", "\n", "Sie sollten einen Wert f\u00fcr k w\u00e4hlen, der die Daten in Folds mit gen\u00fcgend Zeilen aufteilt, so dass jeder Fold immer noch gro\u00df genug ist, um den Originaldatensatzes gut zu repr\u00e4sentieren. Es sollten jedoch immer gen\u00fcgend Folds vorhanden sein, damit die Anzahl der Wiederholungen der Train-Test-Auswertung des Algorithmus ausreicht, um eine angemessene Sch\u00e4tzung der Leistung der Algorithmen zu liefern.\n", "\n", "F\u00fcr Datens\u00e4tze von geringer Gr\u00f6\u00dfe (Hunderte, Tausende oder Zehntausende von Zeilen) ist es eine gute Idee, k=3 f\u00fcr einen kleinen Datensatz oder k=10 f\u00fcr einen gr\u00f6\u00dferen Datensatz zu verwenden. Eine schnelle M\u00f6glichkeit um zu \u00fcberpr\u00fcfen, ob die Fold-Gr\u00f6\u00dfen repr\u00e4sentativ sind, ist die Berechnung von zusammenfassenden Statistiken wie der Mittelwert und die Standardabweichung. So k\u00f6nenn Sie herausfinden, wie sehr sich die Werte von den gleichen Statistiken f\u00fcr den gesamten Datensatz unterscheiden.\n", "\n", "Wir k\u00f6nnen die Gr\u00f6\u00dfe der Folds berechnen, indem wir die Gr\u00f6\u00dfe des Datensatzes durch die Anzahl der erforderlichen Faltungen teilen:  \n", "\n", "$ \\textrm{fold size} = \\frac{\\textrm{Number of rows}}{\\textrm{k}} = \\frac{\\textrm{Number of rows}}{\\textrm{Number of folds}} = \\frac{count(rows)}{count(folds)} $\n", "\n", "Wenn der Datensatz nicht sauber durch die Anzahl der Faltungen geteilt werden kann, kann es einige Restzeilen geben. Diese werden bei der Aufteilung nicht verwendet.\n", "\n", "Nach Durchf\u00fchrung der Kreuzvalidierung erhalten Sie k verschiedene Performanz-Werte, die Sie mit einem Mittelwert und einer Standardabweichung zusammenfassen k\u00f6nnen.  \n", "\n", "Das Ergebnis ist eine zuverl\u00e4ssigere Sch\u00e4tzung der Leistung des Algorithmus auf neuen Daten. Es ist genauer, weil der Algorithmus mehrfach auf verschiedenen Daten trainiert und bewertet wurde.\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Tipp:</b> Wenn Sie nach dem Lesen dieses Abschnitts Probleme haben, die k-fold Cross-Validation zu verstehen. So empfiehlt sich, ein Youtube-Video \u00fcber k-fold Cross-Validation anzuschauen. Die Visualisierung kann Ihnen dabei helfen, den Zusammenhang besser zu verstehen.\n", "</div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Freiwillige Aufgabe:</b> Ihre Aufgabe ist es, die Funktion K-fold Cross-Validation von Grund auf zu implementieren. Der Rest des Codes wird als Anleitung gegeben.\n", "<ul>\n", "<li> Die Funktion erh\u00e4lt den Originaldatensatz und die Anzahl der Folds, die wir erhalten wollen, und gibt eine Liste zur\u00fcck, die die k Folds enth\u00e4lt (in diesem Fall soll sie 4 Faltungen zur\u00fcckgeben).\n", "<li> Wir wollen, dass die Aufteilung zuf\u00e4llig ist, daher m\u00fcssen Sie wahrscheinlich aus dem Modul \"random.py\" (das Teil der Python-Standardbibliothek ist) die Funktionen seed und randrange importieren. Die seed-Funktion wird daf\u00fcr sorgen, dass das Ergebnis von randrange bei jeder Ausf\u00fchrung des Codes gleich ist.\n", "\n", "</ul>\n", "</div>"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["# Example of Creating a Cross Validation Split\n", "from random import seed\n", "from random import randrange\n", "\n", "# Split a dataset into k folds\n", "def cross_validation_split(dataset: pd.DataFrame, folds:int=3):\n", "\n", "    dataset_split = list() # Creates an empty list in \"dataset_split\"\n", "    dataset_copy = list(dataset) # Creates an empty list and copies the dataset in it\n", "    fold_size = int(len(dataset) / folds) # Determine the number of elements for each fold\n", "    print(\"Quantity of elements that each fold will have: \", fold_size)\n", "    # HINT: use a for loop to iterate through the number of folds and use a while loop to populate the individual folds\n", "    # HINT: You might want to use randrange to get a random index of the available dataset\n", "    \n", "    #STUDENT CODE HERE\n", "\n", "    #STUDENT CODE until HERE\n", "    \n", "    return dataset_split\n", "\n", "# test cross validation split\n", "seed(1)\n", "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n", "folds = cross_validation_split(dataset, 4)\n", "print(folds)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["So weit, so gut! Jetzt haben wir verstanden, wie wir die Folds mit unserer eigenen Funktion erzeugen k\u00f6nnen. Aber was w\u00e4re, wenn es eine solche Funktion bereits da drau\u00dfen in der Wildnis g\u00e4be? Tats\u00e4chlich ist das der Fall! Normalerweise codet der Machine-Learning-Ingenieur seine Splits nicht selber, sondern verwendet solche bereits vorhandenen Funktionen. Also probieren wir es aus und verwenden hierbei wieder einmal die Pima-Indians-Diabetes-Datenbank. \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Freiwillige Aufgabe:</b> Berechnen Sie den Mittelwert und die Varianz der Genauigkeit des Modells, um herauszufinden, ob das k gut gew\u00e4hlt wurde, oder ob wir es anpassen sollten. In dieser Aufgabe werden wir ein lineares Regressionsmodell verwenden.\n", "<ul>\n", "<li>Hinweis 1: Die Funktion <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\">cross_val_score</a> kann uns dabei helfen. \n", "<br>\n", "<li>Hinweis 2: Verwenden Sie diese Funktion f\u00fcr die Regression: LogisticRegression (solver = 'liblinear')\n", "\n", "</ul>\n", "</div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Freiwillige Frage:</b> Was passiert mit der Genauigkeit und der Varianz, wenn k zunimmt? Wie k\u00f6nnen Sie die Ver\u00e4nderung der Varianz erkl\u00e4ren?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["# Evaluate using Cross Validation\n", "from pandas import read_csv\n", "from sklearn.model_selection import KFold\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.linear_model import LogisticRegression\n", "\n", "filename = 'data/pima-indians-diabetes.data.csv'\n", "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n", "dataframe = read_csv(filename, names=names)\n", "array = dataframe.values\n", "X = array[:,0:8]\n", "Y = array[:,8]\n", "\n", "#There might be a function which can do \"KFold\" with respect to class distribution. What could be the name?\n", "#Hint: Check the Note below\n", "#Hint: you should be able to do this in less then 5 lines\n", "#Hint: you don't need to explicitly fit your model, because \"cross_val_score\" does this automatically\n", "#STUDENT CODE HERE\n", "\n", "#STUDENT CODE until HERE\n", "\n", "print(results)\n", "\n", "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Geschichtete Zufallsstichprobe (engl. Stratification Sampling)\n", "\n", "Geschichtete Zufallsstichprobe versucht, einen Datensatz so zu unterteilen, dass jede Aufteilung in Bezug auf etwas \u00e4hnlich ist.\n", "\n", "Im Bereich der Klassifizierung wird es oft verwendet um sicherzustellen, dass Trainings- und Testdatens\u00e4tze ungef\u00e4hr den gleichen Prozentsatz an Proben jeder Zielklasse aufweisen wie der vollst\u00e4ndige Datensatz.\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Optionale Aufgabe:</b> F\u00fcgen Sie der Methode train_test_split den Parameter stratify hinzu. \n", "</div>"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["#Save features and targets in a separate data structure\n", "features = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']\n", "target = ['class']\n", "features, targets = diabetes_dataset[features], diabetes_dataset[target]\n", "\n", "#Use the train_test_split function for splitting data.\n", "#Task: Add the correct stratify parameter to the function call\n", "\n", "train_features, test_features, train_targets, test_targets = train_test_split(\n", "        features, targets,\n", "        train_size=0.75,\n", "        test_size=0.25,\n", "        random_state=41, # important for later, do not change yet\n", "        #STUDENT CODE HERE\n", "\n", "        #STUDENT CODE until HERE\n", "    )\n", "\n", "print(\"Proportion of 'targets' in test and train dataset\")\n", "print(\"Training:\", np.bincount(train_targets.values.flatten()) / float(len(train_targets)))\n", "print(\"Test:\", np.bincount(test_targets.values.flatten())/ float(len(test_targets)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Freiwillige Aufgabe:</b> Was haben wir durch das stratifizierte Sampling erreicht? Schauen Sie sich die Ausgabe des vorherigen Codeblocks an und beschreiben Sie diese mit eigenen Worten. \n", "\n", "(Besprechen Sie dies mit Ihrem Partner, bevor Sie anfangen, etwas zu googeln wie: \"stratification machine learning\")\n", "</div>\n", "\n", "\n", "<div class=\"alert block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Ausw\u00e4hlen einer Resampling-Methode\n", "\n", "- Allgemeinen ist die k-fold Cross-Validation der Goldstandard f\u00fcr die Bewertung der Performanz eines Algorithmus des maschinellen Lernens, wobei k auf 3, 5 oder 10 gesetzt wird.  \n", "Wenn sie gut konfiguriert ist, liefert die k-fold Cross-Validation eine robuste Sch\u00e4tzung der Leistung im Vergleich zu anderen Methoden, wie z. B. der Aufteilung in Train und Test. Der Nachteil der Kreuzvalidierung ist, dass sie zeitaufw\u00e4ndig sein kann, da k verschiedene Modelle trainiert und ausgewertet werden m\u00fcssen. Dies ist ein Problem, wenn Sie einen sehr gro\u00dfen Datensatz haben oder wenn Sie ein Modell evaluieren, dessen Training sehr lange dauert.  \n", "\n", "\n", "- Die Trainings- und Test-Split Resampling-Methode wird am h\u00e4ufigsten verwendet. Der Grund daf\u00fcr ist, dass sie einfach zu verstehen und zu implementieren ist. Sie f\u00f6rdert die Geschwindigkeit, wenn ein langsamer Algorithmus verwendet wird, da nur ein einziges Modell konstruiert und ausgewertet wird. \n", "Diese Methode kann eine verrauschte oder unzuverl\u00e4ssige Sch\u00e4tzung der Leistung liefern, aber das wird weniger zum Problem, wenn Sie einen sehr gro\u00dfen Datensatz verwenden. In diesem Fall erzeugt dieser Ansatz geringere Verzerrung.\n", "Gro\u00dfe Datens\u00e4tze haben Hunderttausenden oder Millionen von Eintr\u00e4gen, und sind damit so gro\u00df, dass die Training- und Test-Splits nahezu die gleichen statistischen Eigenschaften aufweisen.\n", "In solchen F\u00e4llen ist die Verwendung der k-fold Cross-Validation zur Evaluierung des Algorithmus m\u00f6glicherweise nicht notwendig und eine Aufteilung in Train und Test kann genauso zuverl\u00e4ssig sein.\n", "\n", "\n", "- Verfahren wie die Leave-One-Out-Cross-Validation und wiederholte zuf\u00e4llige Splits k\u00f6nnen n\u00fctzliche Zwischenstufen sein, um einen Mittelweg zwischen der Varianz der gesch\u00e4tzten Performanz, der Trainingsgeschwindigkeit des Modells und der Gr\u00f6\u00dfe des Datensatzes zu finden.\n", "\n", "Es ist sinnvoll, verschiedene M\u00f6glichkeiten auszuprobieren, um eine Technik f\u00fcr ihr Problem zu finden, die schnell ist, aber gleichzeitig auch eine vern\u00fcnftige Sch\u00e4tzungen der Performanz liefert, auf Basis derer sie dann eine Entscheidung treffen k\u00f6nnen. Im Zweifelsfall sollten Sie die 10-fold Cross-Validation verwenden.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.3"}}, "nbformat": 4, "nbformat_minor": 4}