{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Wie geht's eigentlich weiter?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Einf\u00fchrung und \u00dcberblick\n", "\n", "In dieser Aufgabe lernen Sie die Grundlagen zur Entwicklung rekurrenter neuronaler Netze (RNN), speziell Long Short-Term Memory Networks (LSTM). Diese Art von Algorithmen sind wegen ihrer F\u00e4higkeit, zeitliche Abh\u00e4ngigkeiten in Daten zu beschreiben, sehr bekannt. Wenn Sie versuchen, ein Signal oder die Reaktion eines kausalen Systems zu modellieren, sind RNNs normalerweise eine der ersten Optionen, die Sie in Betracht ziehen (zusammen mit typischen statistischen Methoden wie linearen Regressionen, exponentieller Gl\u00e4ttung, ARIMA-Modellen usw., die in dieser Aufgabe nicht ber\u00fccksichtigt werden). Durch die rekursiven Verbindungen in diesem neuronalen Netz entsteht eine Art Ged\u00e4chtnis, das Zeitreihen gut beschreibt. Dies ist besonders hilfreich im Hinblick auf Prognosen. Prognosen werden von vielen Unternehmen verwendet, um bei der Budgetierung, der Planung und der Absch\u00e4tzung des zuk\u00fcnftigen Wachstums zu helfen. Mit anderen Worten, es ist der Versuch, zuk\u00fcnftige Ergebnisse auf der Grundlage vergangener Ereignisse vorherzusagen.\n", "\n", "Diese Arbeit ist wie folgt aufgebaut: Zun\u00e4chst werden einige theoretische Hintergr\u00fcnde zur Zeitreihenanalyse und -prognose gegeben. Dann wird auf die Datenvorbereitung f\u00fcr Zeitreihen eingegangen, was der erste Schritt ist, den man vor Beginn eines jeden Prognoseprojekts machen muss. Danach wird der interessanteste Teil erkl\u00e4rt: LSTMs. Wir werden zun\u00e4chst ein einfaches Vanilla-LSTM betrachten, mit einem Hidden Layer. Danach werden wir mehrere Layers stapeln und die Ergebnisse mit der Vanilla-L\u00f6sung vergleichen. Am Ende werden Sie einen TV-Skript-Generator erforschen und dabei Ihr erworbenes Wissen \u00fcber Zeitreihen und LSTM-Netzwerke anwenden."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Zeitreihenvorhersage\n", "Eine Zeitreihe ist eine Folge von Beobachtungen, die zeitlich aufeinander folgen. Diese Beobachtungen sind normalerweise Messungen in Form von numerischen Werten. Zum Beispiel kann der alle f\u00fcnf Minuten gemessene Batteriestand eines Elektroautos als Zeitreihe ausgedr\u00fcckt werden. \n", "\n", "### Beschreiben vs. Vorhersagen\n", "Das Verstehen eines Datensatzes, in diesem Fall Zeitreihenanalyse genannt, ist ein wichtiger Schritt, bevor man mit der Arbeit des Datensatzes beginnt. Dies kann helfen, bessere Vorhersagen zu treffen. Eine tiefe Zeitreihenanalyse ist jedoch nicht erforderlich, da sie zu einem gro\u00dfen technischen Aufwand, Zeit und Fachwissen f\u00fchren kann, die nicht direkt mit dem gew\u00fcnschten Ergebnis, n\u00e4mlich der Vorhersage der Zukunft, \u00fcbereinstimmt.\n", "\n", "Bei der deskriptiven Modellierung oder __Zeitreihenanalyse (engl. time series analysis)__ wird eine Zeitreihe modelliert, um ihre Komponenten in Bezug auf saisonale Muster, Trends, Beziehung zu externen Faktoren und dergleichen zu bestimmen. Im Gegensatz dazu nutzt die __Zeitreihenprognose (engl. time series forecasting)__ die Informationen in einer Zeitreihe (oft zusammen mit zus\u00e4tzlichen Informationen), um zuk\u00fcnftige Werte der Reihe zu prognostizieren.[4]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Problem Definition\n", "Im folgenden Tutorial werden Sie mit einem einfachen Datensatz der elektrischen Last in Deutschland in MWh von Oktober 2017 bis Oktober 2019 arbeiten. Das Ziel dieser Aufgabe ist es, die Last f\u00fcr eine Woche mit LSTMs zu prognostizieren. \n", "\n", "Erkunden Sie zun\u00e4chst den gegebenen Datensatz. Laden Sie die csv-Datei *Load_DE_2017_2019.csv*, geben Sie einige Datenelemente aus, pr\u00fcfen Sie die Gr\u00f6\u00dfe der Datei, verwenden Sie die Funktion __[describe()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)__ von Pandas, um Mittelwert, Standardabweichung, Median, Minimum und Maximum der Beobachtungen zu pr\u00fcfen. Dies kann helfen, eine Vorstellung von der Verteilung und Streuung der Werte zu bekommen. Dies kann Ihnen auch einige Ideen zur Datenskalierung und sogar zur Datenbereinigung geben, die Sie sp\u00e4ter als Teil der Vorbereitung Ihres Datensatzes f\u00fcr die Modellierung durchf\u00fchren k\u00f6nnen.\n", "\n", "In dieser Aufgabe werden wir Series von Pandas als Datenstruktur verwenden. Weitere Informationen finden Sie in der offiziellen Pandas-Dokumentation [Intro to Data Structures](http://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 6.3.1:</b> Vervollst\u00e4ndigen Sie die folgenden Code-Zellen entsprechend den darin enthaltenen Kommentaren.\n", "\n", "</div>"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["from pandas import read_csv\n", "import pandas as pd\n", "\n", "# Load the dataset using read_csv() with \n", "# squeeze=True to return a Series instead of a DataFrame\n", "# parse_dates=True, dayfirst=True to convert the date to a datetime column\n", "# index_col=0 to consider the date as index\n", "# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE\n", "\n", "# Use the function to_numeric with treating errors as 'coerce' from pandas in order to read the values of the dataset as floats\n", "# And fill the NANs in the dataset using the method \"ffil\" with downcast as \"infer\"\n", "# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Check that a Series data type (and not a DataFrame) was created\n", "print(type(series))"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Print some rows of the dataset (Hint: use .head() for this)\n", "# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# Check the size of the series (Hint: use .size for this)\n", "# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# Check something else from the series if you are curious...\n", "# For example print the data from October\n", "# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# Calculate descriptive statistics on your time series using describe()\n", "# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Taxonomie von Zeitreihenprognosen-Problemen\n", "\n", "Um das Verst\u00e4ndnis des Prognoseproblems zu verbessern, ist die Struktur des Modells erforderlich und es ist notwendig zu wissen, wie man es auswertet. Daher wird empfohlen, die folgenden Schl\u00fcsselpunkte zu ber\u00fccksichtigen, bevor ein Projekt zur Zeitreihenprognose gestartet wird [2]:\n", "\n", "- __Eingabedaten vs. Ausgabedaten__: Die Eingabedaten sind die Werte, die zur Erstellung einer Prognose verwendet werden. Zum Beispiel die Verkaufsdaten der letzten sieben Tage, um den Umsatz des n\u00e4chsten Tages zu prognostizieren. Die Eingabedaten sind nicht die Daten, die zum Trainieren des Modells, sondern zum Testen/Vorhersagen verwendet werden.<br>\n", "    Die Ausgabedaten entsprechen der Vorhersage oder Prognose f\u00fcr einen zuk\u00fcnftigen Zeitschritt, der \u00fcber die als Eingabe bereitgestellten Daten hinausgeht.<br>\n", "    Die Definition der Ein- und Ausgabedaten des Modells zwingt Sie dazu, sich Gedanken dar\u00fcber zu machen, was genau ben\u00f6tigt wird oder werden k\u00f6nnte, um eine Prognose zu erstellen. M\u00f6glicherweise k\u00f6nnen Sie bei den Eingabedaten nicht genau sein. Sie k\u00f6nnen z. B. nicht wissen, ob ein oder mehrere vorherige Zeitschritte erforderlich sind, um eine Prognose zu erstellen. Aber Sie werden in der Lage sein, die Variablen zu identifizieren, die einen Einfluss auf den Prognoseprozess haben k\u00f6nnten.\n", "\n", "- __Endogene vs. Exogene Eingangsvariablen__: Eine Eingangsvariable ist endogen, wenn sie von anderen Variablen im System beeinflusst wird und die Ausgangsvariable von ihr abh\u00e4ngt. In einer Zeitreihe zeigen die Beobachtungen einer Eingangsvariablen Abh\u00e4ngigkeiten in sich selbst. Zum Beispiel ist die Beobachtung zum Zeitpunkt *t* abh\u00e4ngig von der Beobachtung zum Zeitpunkt _t-1_; _t-1_ kann von _t-2_ abh\u00e4ngen, und so weiter. <br>\n", "    Eine Eingangsvariable ist eine exogene Variable, wenn sie unabh\u00e4ngig von anderen Variablen im System ist und die Ausgangsvariable von ihr abh\u00e4ngt. Vereinfacht ausgedr\u00fcckt, werden endogene Variablen von anderen Variablen im System (einschlie\u00dflich ihrer selbst) beeinflusst, w\u00e4hrend exogene Variablen dies nicht sind und als au\u00dferhalb des Systems betrachtet werden.<br>\n", "    Typischerweise hat ein Zeitreihenprognoseproblem endogene Variablen (z. B. ist die Ausgabe eine Funktion einer gewissen Anzahl von vorherigen Zeitschritten) und kann exogene Variablen haben oder auch nicht. Oft werden die exogenen Variablen ignoriert. Das explizite Nachdenken \u00fcber beide Variablentypen kann helfen, leicht zu \u00fcbersehende exogene Daten oder sogar technische Features zu identifizieren, die das Modell verbessern k\u00f6nnen.\n", "    \n", "- __Unstrukturiert vs. Strukturiert__: Es ist n\u00fctzlich, jede Variable in einer Zeitreihe darzustellen und die Darstellung auf m\u00f6gliche Muster zu untersuchen. Eine Zeitreihe f\u00fcr eine einzelne Variable weist m\u00f6glicherweise kein offensichtliches Muster auf. Wir k\u00f6nnen eine Reihe ohne Muster als unstrukturiert betrachten, da es keine erkennbare zeitabh\u00e4ngige Struktur gibt. <br>\n", "    Alternativ dazu kann eine Zeitreihe offensichtliche Muster aufweisen und in vier Bestandteile zerlegt werden: \n", "    - Level: Der Basiswert der Reihe, wenn sie eine Gerade w\u00e4re.\n", "    - Trend: Das optionale und oft linear ansteigende oder abfallende Verhalten der Reihe \u00fcber die Zeit.\n", "    - Saisonalit\u00e4t: Die optionalen sich wiederholenden Muster oder Zyklen des Verhaltens im Zeitverlauf.\n", "    - Rauschen: Die optionale Variabilit\u00e4t in Beobachtungen, die nicht durch das Modell erkl\u00e4rt werden kann.<br>\n", "    \n", "- __Regression vs. Klassifikation__: Bei Regressionsvorhersagemodellen handelt es sich um Probleme, bei denen eine Quantit\u00e4t vorhergesagt wird. Eine Quantit\u00e4t ist ein numerischer Wert, z. B. ein Preis, eine Anzahl, ein Volumen usw. Ein Zeitreihen-Prognoseproblem, bei dem Sie einen oder mehrere zuk\u00fcnftige numerische Werte vorhersagen m\u00f6chten, ist ein Regressions-Prognosemodellierungsproblem. <br>\n", "    Klassifikationspr\u00e4diktive Modellierungsprobleme sind solche, bei denen eine Kategorie vorhergesagt wird. Eine Kategorie ist eine Bezeichnung aus einer kleinen, wohldefinierten Menge von Bezeichnungen. Zum Beispiel sind \"hei\u00df\", \"kalt\", \"aufw\u00e4rts\", \"abw\u00e4rts\", \"kaufen\" und \"verkaufen\" Kategorien. Ein Zeitreihenprognoseproblem, bei dem Sie die eingegebenen Zeitreihendaten klassifizieren m\u00f6chten, ist ein Prognosemodellierungsproblem vom Typ Klassifikation. <br>\n", "    Zwischen diesen Typen gibt es eine gewisse Flexibilit\u00e4t. So kann z. B. ein Regressionsproblem in ein Klassifizierungsproblem und ein Klassifizierungsproblem in eine Regression umgewandelt werden. Einige Probleme, wie z. B. die Vorhersage eines Ordinalwerts, k\u00f6nnen sowohl eine Klassifizierung als auch eine Regression zugeordnet werden. Es ist m\u00f6glich, dass eine Neuausrichtung Ihres Zeitreihen-Prognoseproblems dieses vereinfachen kann.\n", "\n", "- __Univariat vs. Multivariat__:  Eine einzelne Variable, die \u00fcber die Zeit gemessen wird, wird als univariate Zeitreihe bezeichnet. Mehrere Variablen, die \u00fcber die Zeit gemessen werden, werden als multivariate Zeitreihen bezeichnet. Die Betrachtung dieser Frage in Bezug auf Inputs und Outputs kann zu einer weiteren Unterscheidung f\u00fchren. Die Anzahl der Variablen kann sich zwischen den Inputs und Outputs unterscheiden, d. h. die Daten sind m\u00f6glicherweise nicht symmetrisch. Es kann z. B. sein, dass Sie mehrere Variablen als Input f\u00fcr das Modell haben und nur an der Vorhersage einer der Variablen als Output interessiert sind. In diesem Fall besteht im Modell die Annahme, dass die mehreren Eingabevariablen das Modell selbst verbessern und f\u00fcr die Vorhersage der einzelnen Ausgabevariablen erforderlich sind.\n", "\n", "- __Einschrittig vs. Mehrschrittig__: Ein Prognoseproblem, das eine Vorhersage des n\u00e4chsten Zeitschritts erfordert, wird als einschrittiges Prognosemodell bezeichnet. Ein Prognoseproblem, das eine Vorhersage von mehr als einem Zeitschritt erfordert, wird hingegen als mehrschrittiges Prognosemodell bezeichnet. Je mehr Zeitschritte in die Zukunft projiziert werden m\u00fcssen, desto schwieriger wird das Problem, da sich die Unbestimmtheit in jedem prognostizierten Zeitschritt erh\u00f6ht.\n", "\n", "- __Statisch vs. Dynamisch__: Es ist m\u00f6glich, ein Modell einmal zu entwickeln und es wiederholt f\u00fcr Vorhersagen zu verwenden. Da das Modell zwischen den Prognosen nicht aktualisiert oder ge\u00e4ndert wird, kann man dieses Modell als statisch betrachten. Umgekehrt k\u00f6nnen wir neue Beobachtungen erhalten, bevor wir eine nachfolgende Vorhersage machen, die zur Erstellung eines neuen Modells oder zur Aktualisierung des vorhandenen Modells verwendet werden k\u00f6nnen. Wir k\u00f6nnen die Entwicklung eines neuen oder aktualisierten Modells vor jeder Prognose als ein dynamisches Problem betrachten.\n", "\n", "- __Kontinuierlich vs. Diskontinuierlich__: Eine Zeitreihe, bei der die Beobachtungen \u00fcber die Zeit gleichm\u00e4\u00dfig sind, kann als kontinuierlich beschrieben werden. Viele Zeitreihenprobleme haben kontinuierlich Beobachtungen, z. B. eine Beobachtung pro Stunde, Tag, Monat oder Jahr. Eine Zeitreihe, bei der die Beobachtungen im Laufe der Zeit nicht einheitlich sind, kann als diskontinuierlich bezeichnet werden. Die fehlende Gleichm\u00e4\u00dfigkeit der Beobachtungen kann durch fehlende oder fehlerhafte Werte verursacht werden. Sie kann auch dadurch bedingt sein, dass Beobachtungen nur sporadisch oder in immer k\u00fcrzeren Zeitabst\u00e4nden zur Verf\u00fcgung gestellt werden. Im Falle von uneinheitlichen Beobachtungen kann bei der Anpassung einiger Modelle eine spezielle Datenformatierung erforderlich sein, um die Beobachtungen \u00fcber die Zeit zu vereinheitlichen."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe/Frage 6.3.2:</b> Jetzt sind Sie an der Reihe. Bewerten Sie die Taxonomie des vorgeschlagenen Vorhersageproblems der elektrischen Last in Deutschland. Beschreiben Sie kurz dieses Problems anhand der oben genannten Stichpunkte.\n", "</div>\n", "\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Datenaufbereitung"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Zerlegen von Zeitreihendaten\n", "Man geht davon aus, dass eine gegebene Zeitreihe aus drei systematischen Komponenten besteht, einschlie\u00dflich __Level__, __Trend__, __Saisonalit\u00e4t__, und einer nicht systematischen Komponente, die __Rauschen__ genannt wird. Man geht davon aus, dass eine Reihe ein Aggregat oder eine Kombination aus diesen vier Komponenten besteht. Alle Reihen haben ein Level und ein Rauschen. Die Komponenten Trend und Saisonalit\u00e4t sind optional. In diesem Abschnitt werden Methoden zur automatischen Zerlegung einer Zeitreihe erl\u00e4utert.\n", "\n", "Die Bibliothek [Statsmodels](https://www.statsmodels.org/stable/index.html) bietet eine Implementierung der naiven oder klassischen Zerlegungsmethode in einer Funktion namens `seasonal_decompose()`. Sie erfordert die Angabe, ob das Modell additiv oder multiplikativ ist. \n", "\n", "__Wichtig:__ Diese Funktion erzeugt eine naive Dekomposition. F\u00fcr weitergehende Analysen sollten anspruchsvollere Methoden bevorzugt werden.<br>\n", "Das additive Modell wird beschrieben als Y[t] = T[t] + S[t] + e[t]<br>\n", "Das multiplikative Modell ist Y[t] = T[t] * S[t] * e[t]<br>\n", "Die saisonale Komponente wird zun\u00e4chst durch Anwendung eines Faltungsfilters auf die Daten entfernt. Der Durchschnitt dieser gegl\u00e4tteten Reihe f\u00fcr jede Periode ist die zur\u00fcckgegebene saisonale Komponente.<br>\n", "\n", "Wenn die Art des Zerlegungsmodells unbekannt ist, kann eine \u00dcberpr\u00fcfung eines Plots der Zeitreihe und einiger zusammenfassender Statistiken oft ein guter Anfang sein. Diese geben eine Vorstellung davon, ob das Zeitreihenproblem additiv oder multiplikativ aussieht.\n", "\n", "Abbildung 1 zeigt zwei verschiedene Zeitreihen, die mit der additiven (links) und multiplikativen (rechts) Methode zerlegt werden k\u00f6nnen. Betrachten Sie die Form der Reihen und wie unterschiedlich sie sind. \n", "\n", "<img src=\"images\\Additive-Multiplicative-Decomposition-time-series.png\" alt=\"drawing\" style=\"width:700px;\"/>\n", "<p style=\"text-align: center;\">\n", "    Abb. 1 - Beispiel f\u00fcr eine additive (links, [10]) und eine multiplikative Zerlegung von Zeitreihen (rechts, [1]).\n", "</p>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Im folgenden Schnipsel sehen Sie den Code f\u00fcr eine additive saisonale Zerlegung."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 6.3.3:</b> Vervollst\u00e4ndigen Sie den Code, um alle Komponenten in einem Graph darzustellen. Schreiben Sie auch einen Code, um eine einzelne Komponente in einem Diagramm darzustellen, z. B. den Trend.\n", "<ul>\n", "<li>Hinweis: <code>sm.tsa.seasonal_decompose</code> liefert ein DecomposeResult. Dieses hat die Attribute <i>observed, trend, seasonal</i> und <i>resid</i>, die Pandas-Reihen sind. Sie k\u00f6nnen jede von ihnen mit der Pandas-Plot-Funktionalit\u00e4t darstellen.\n", "\n", "\n", "</ul>\n", "\n", "</div>"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["from statsmodels.tsa.seasonal import seasonal_decompose\n", "from matplotlib import pyplot\n", "\n", "result_add = seasonal_decompose(series[:2000], model='additive', period=96)\n", "trend_add = result_add.trend\n", "seasonality_add = result_add.seasonal\n", "residual_add = result_add.resid\n", "original_data = result_add.observed"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["# Plot all components of the time series\n", "# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["# Plot a single component. For example the seasonality\n", "# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe/Frage 6.3.4:</b> Zerlegen Sie das gleiche Signal mit dem multiplikativen Modell und vergleichen Sie. Was k\u00f6nnen Sie aus beiden Zerlegungsmodellen schlie\u00dfen?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["# Multiplicative Decomposition\n", "# Plot all components of the time series\n", "# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["# Plot a single component\n", "# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Datennormalisierung\n", "Die Normalisierung ist eine Neuskalierung der Daten aus ihrem urspr\u00fcnglichen Bereich, so dass alle Werte im Bereich von 0 und 1 liegen. Dies hilft dem neuronalen Netz, die Trends der Daten leichter zu lernen. \n", "\n", "Die Bibliothek _Scikit-learn_ verf\u00fcgt \u00fcber ein Tool namens *MinMaxScaler*, das zum Skalieren der Daten verwendet werden kann. Die n\u00e4chsten Schritte sind die __allgemeinen Schritte__, die zu befolgen sind:\n", "- Passen Sie den Skalierer anhand der verf\u00fcgbaren Trainingsdaten an. F\u00fcr die Normalisierung bedeutet dies, dass die Trainingsdaten verwendet werden, um die minimalen und maximalen beobachtbaren Werte zu sch\u00e4tzen. Dies geschieht durch den Aufruf der Methode `fit()`.\n", "- Wenden Sie die Skalierung auf die Trainingsdaten an, um die normalisierten Daten zum Trainieren Ihres Modells zu verwenden. Dies geschieht durch den Aufruf der Methode `transform()`.\n", "- Wenden Sie die Skalierung auf die Daten an, die f\u00fcr den Vorw\u00e4rtsdurchlauf verwendet werden. Dies bereitet die Daten vor, die Sie f\u00fcr die Vorhersagen verwenden werden."]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import MinMaxScaler\n", "\n", "# Prepare data for normalization\n", "values = series.values\n", "values = values.reshape((len(values), 1))\n", "\n", "# Train the normalization\n", "scaler = MinMaxScaler(feature_range=(0, 1))\n", "scaler = scaler.fit(values)\n", "print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n", "\n", "# Normalize the dataset and print\n", "normalized = scaler.transform(values)\n", "print(\"Normalized values:\\n %s\" %(normalized))\n", "\n", "# Inverse transform and print\n", "inversed = scaler.inverse_transform(normalized)\n", "print(\"Denormalized values:\\n %s\" %(inversed))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Datenstandardisierung\n", "Bei der Standardisierung eines Datensatzes wird die Verteilung der Werte so skaliert, dass der Mittelwert der beobachteten Werte gleich 0 und die Standardabweichung gleich 1 ist. Dies kann als Subtraktion des Mittelwerts oder als Zentrierung der Daten betrachtet werden. Wie die Normalisierung kann auch die Standardisierung n\u00fctzlich und in einigen Algorithmen f\u00fcr maschinelles Lernen sogar erforderlich sein, wenn Ihre Daten Eingabewerte mit unterschiedlichen Skalen aufweisen. Bei der Standardisierung wird davon ausgegangen, dass Ihre Beobachtungen einer Gau\u00df-Verteilung (Glockenkurve) mit einem gut verhaltenen Mittelwert und einer Standardabweichung entsprechen. Sie k\u00f6nnen Ihre Zeitreihendaten auch dann standardisieren, wenn diese Erwartung nicht erf\u00fcllt ist, aber Sie erhalten m\u00f6glicherweise keine zuverl\u00e4ssigen Ergebnisse.<br>\n", "Sie k\u00f6nnen Ihren Datensatz mithilfe des *scikit-learn*-Objekts *StandardScaler* standardisieren."]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler\n", "from math import sqrt\n", "\n", "# Train the standardization\n", "scaler = StandardScaler()\n", "scaler = scaler.fit(values)\n", "print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, sqrt(scaler.var_)))\n", "\n", "# Normalize the dataset and print\n", "standardized = scaler.transform(values)\n", "print(\"Standardized values:\\n %s\" %(standardized))\n", "\n", "# Inverse transform and print\n", "inversed = scaler.inverse_transform(standardized)\n", "print(\"De-standardized values:\\n %s\" %(inversed))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Zus\u00e4tzliche Ressourcen zur Datenaufbereitung und Zeitreihenprognose\n", "\n", "Die folgenden Artikel helfen Ihnen weiter, falls Sie tiefer in die Zeitreihenprognose einsteigen m\u00f6chten:\n", "\n", "- [Open Machine Learning Course - Time series analysis in Python](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic09_time_series/topic9_part1_time_series_python.ipynb) von Dmitriy Sergeyev\n", "- [7 Ways Time Series Forecasting Differs from Machine Learning](https://www.datascience.com/blog/time-series-forecasting-machine-learning-differences) verfasst von Roman de las Heras\n", "- [Data Science for Business - Time Series Forecasting Part 1: EDA & Data Preparation](https://shiring.github.io/forecasting/2017/05/28/retail_forcasting_part1) "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Limitationen von mehrschichtigen Perzeptronen (engl. Multilayer Perceptrons)\n", "Trotz ihrer Flexibilit\u00e4t und Leistungsf\u00e4higkeit funktionieren Feed-Forward-Neuronale Netze nur f\u00fcr Probleme gut, deren Eingaben und Targets sinnvoll mit Vektoren fester Dimensionalit\u00e4t kodiert werden k\u00f6nnen. Dies ist eine erhebliche Einschr\u00e4nkung, da viele wichtige Probleme am besten mit Sequenzen ausgedr\u00fcckt werden, deren L\u00e4nge nicht von vornherein bekannt ist. Zum Beispiel sind Spracherkennung und maschinelle \u00dcbersetzung sequenzielle Probleme. Ebenso kann das Beantworten von Fragen auch als das Abbilden einer Folge von W\u00f6rtern angesehen werden, die die Frage darstellen zu einer Folge von W\u00f6rtern, die die Antwort darstellen. [5]\n", "\n", "Aus dem Stand der Technik ist auch bekannt, dass MLPs schlecht abschneiden, wenn das zu l\u00f6sende Problem zeitliche Abh\u00e4ngigkeiten aufweist, wie es bei Zeitreihen-Prognoseproblemen h\u00e4ufig der Fall ist. Dies ist auf den Mangel an Langzeitspeicher im Netzwerk zur\u00fcckzuf\u00fchren. F\u00fcr diese Art von Anwendungen haben sich rekurrente neuronale Netze als leistungsf\u00e4higer erwiesen als MLPs. Diese Art von Netzwerken wird in diesem Abschnitt beschrieben."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Rekurrente Neurale Netzwerke\n", "Rekurrente neuronale Netze (RNNs) enthalten Zyklen, die die Aktivierungen der Neuronen aus einem vorherigen Zeitschritt als Eingaben in das Netz einspeisen. Dies geschieht, um Vorhersagen zum aktuellen Zeitschritt zu beeinflussen. Diese Aktivierungen werden in den internen Zust\u00e4nden des Netzes gespeichert, die prinzipiell langfristige zeitliche Kontextinformationen enthalten k\u00f6nnen. Dieser Mechanismus erlaubt es RNNs, ein sich dynamisch ver\u00e4nderndes Kontextfenster \u00fcber die Eingangssequenzhistorie auszunutzen. [6]\n", "\n", "Um zu verstehen, wie RNNs den inneren Zustand der Zellen als rekurrenten Input einspeisen, zeigt Abbildung 2 [11] die m\u00f6glichen Architekturen, die RNNs in Abh\u00e4ngigkeit von verschiedenen Anwendungen haben k\u00f6nnen. In dieser Abbildung ist das Netzwerk in der Zeit abgerollt dargestellt, d. h. die horizontale Achse stellt die Zeit und die vertikale Achse die Tiefe des Netzwerks dar. Zu Lehrzwecken gibt es in allen Architekturdarstellungen in Abbildung 2 nur ein Hidden Layer mit einer Zelle. Im Folgenden sind einige Anwendungsbeispiele f\u00fcr jede Architektur aufgef\u00fchrt: \n", "\n", "- 1:1 : Diese Architektur beschreibt, wie Vanilla Feed Forward neuronale Netzwerke arbeiten. Sie haben eine Eingabe, alle Neuronen sind ohne Rekursion mit dem n\u00e4chsten Neuron verbunden und es wird nur eine Ausgabe erwartet. \n", "- 1:n : Dies ist z. B. der Fall bei Bildbeschriftungen. In diesem Fall kommt ein einzelnes Bild herein und als Ausgabe wird eine Phrase (eine Menge von W\u00f6rtern) erwartet. Die rekursiven Verbindungen von Zelle zu Zelle geben dem Netz die M\u00f6glichkeit, das n\u00e4chste Wort in Abh\u00e4ngigkeit von den letzten Ausgaben genauer zu bestimmen, um einen (prinzipiell) sinnvollen Text zu erzeugen. \n", "- n:1 : Eine solche Architektur kann f\u00fcr die Sentiment-Analyse verwendet werden. In diesem Fall wird ein Text in Form von W\u00f6rtern oder Zeichen in das Netzwerk eingegeben und das entsprechend ausgedr\u00fcckte Sentiment als Ausgabe erwartet. \n", "- n:n : Zwei Anwendungsbeispiele f\u00fcr diese Architektur sind zum einen die Sprach\u00fcbersetzung (Text als Eingabe, Text als Ausgabe) auf Zeichen- oder Wortebene und zum anderen die Videoklassifikation auf Frame-Ebene, bei der eine Frame-Beschriftung in Abh\u00e4ngigkeit von vergangenen Frames erfolgt. \n", "\n", "<img src=\"images\\RNN-architectures.png\" alt=\"drawing\" style=\"width:1000px;\"/>\n", "<p style=\"text-align: center;\">\n", "    Abb. 2 - Architekturen neuronaler Netze: Die 1:1-Architektur entspricht einem Vanilla Neural Network, w\u00e4hrend die F\u00e4lle 1:n, n:1 und n:n die Strukturen rekurrenter neuronaler Netze beschreiben [11].\n", "</p>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Long Short-Term Memory Netzwerke\n", "Long short-term memory Netzwerke (LSTM) sind eine Untergruppe der rekurrenten neuronalen Netze, aber im Gegensatz zu allgemeinen RNNs haben LSTMs eine einzigartige Formulierung, die es ihnen erm\u00f6glicht, die Probleme der verschwindenden und ausnutzenden Gradienten (Gewichts\u00e4nderungen, die schnell so klein werden, dass sie keine Wirkung mehr haben, oder so gro\u00df, dass sie zu einem \u00dcberlauf f\u00fchren) zu vermeiden. [3]  \n", "\n", "In den folgenden Teilen dieser Arbeit wird das LSTM zun\u00e4chst als Vanilla-Version (einzelnes Hidden Layer) behandelt, um die Grundlagen seiner Entwicklung zu verstehen. Danach werden mehrere Schichten \u00fcbereinander gelegt, um kompliziertere Probleme zu l\u00f6sen.  \n", "\n", "### LSTM Zelle \n", "Eine LSTM-Zelle (auch Speicherzelle genannt) hat Gewichtungsparameter f\u00fcr den Eingang, den Ausgang und f\u00fcr den internen Zustand. Sie werden durch die Exposition gegen\u00fcber den Eingaben in jedem Zeitschritt aufgebaut und bei der Berechnung der Ausgabe(n) verwendet.\n", "Der Schl\u00fcssel zur Speicherzelle sind die Gates. Auch diese sind gewichtete Funktionen, die den Informationsfluss in der Zelle weiter steuern. <br>\n", "In einer LSTM-Zelle gibt es drei Gates, wie in Abbildung 3 zu sehen ist:\n", "- Forget-Gate: Entscheidet, welche Informationen in der Zelle verworfen werden.\n", "- Input-Gate: Entscheidet, welche Werte von der Eingabe verwendet werden, um den Speicherzustand zu aktualisieren.\n", "- Ausgangs-Gate: Entscheidet, was basierend auf dem Eingang und dem Speicher der Zelle ausgegeben werden soll. [3]<br>\n", "\n", "<img src=\"images\\LSTM-description-block.png\" alt=\"drawing\" style=\"width:1000px;\"/>\n", "<p style=\"text-align: center;\">\n", "    Abb. 3 - Detailliertes Schema der Einheit eines einfachen rekurrenten Netzwerks (RNN) (links) und einer Speicherzelle (rechts), wie sie in den Hidden Layers eines LSTMs verwendet werden. [7]\n", "</p>\n", "\n", "\n", "### Limitationen von LSTM\n", "Eine wichtige Einschr\u00e4nkung von LSTMs ist die M\u00f6glichkeit, den Speicher zu missbrauchen. Es ist m\u00f6glich, ein LSTM-Modell dazu zu zwingen, sich eine einzelne Beobachtung \u00fcber eine sehr lange Anzahl von Eingabezeitschritten zu merken. Dies ist eine schlechte Nutzung von LSTMs. Wenn man von einem LSTM-Modell verlangt, sich mehrere Beobachtungen zu merken, wird es scheitern. Das kann man sehen, wenn man LSTMs auf Zeitreihenvorhersagen anwendet, bei denen das Problem als Autoregression formuliert ist, die erfordert, dass die Ausgabe eine Funktion von mehreren entfernten Zeitschritten in der Eingabesequenz ist. Ein LSTM kann gezwungen werden, dieses Problem zu l\u00f6sen, wird aber im Allgemeinen weniger effizient sein als ein sorgf\u00e4ltig entworfenes Autoregressionsmodell."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Vanilla LSTM\n", "Das neuronale Netzwerk LSTM kann f\u00fcr univariate Zeitreihenprognosen verwendet werden. Wie ein RNN liest es jeden Zeitschritt einer Eingabesequenz schrittweise ein. Das LSTM hat einen internen Speicher, der es ihm erm\u00f6glicht, interne Zust\u00e4nde zu akkumulieren, w\u00e4hrend es die Schritte einer gegebenen Eingabesequenz liest. Am Ende der Sequenz gibt jeder Knoten in einer Schicht von versteckten LSTM-Einheiten (engl. hidden units) einen einzelnen Wert aus. Dieser Vektor von Werten fasst zusammen, was das LSTM gelernt oder aus der Eingabesequenz extrahiert hat. Dies kann von einer vollst\u00e4ndig verbundenen Schicht (engl. fully connected layer) interpretiert werden, bevor eine endg\u00fcltige Vorhersage getroffen wird. [3]\n", "\n", "Das folgende Modell umfasst ein einzelnes LSTM-Layer, gefolgt von einer vollst\u00e4ndig verbundenen Outputlayer (Dense), wie in Abbildung 4 zu sehen. Dies ist die LSTM-Architektur, die im urspr\u00fcnglichen LSTM Paper von 1997 [8] definiert wurde, und die Architektur, die bei den meisten kleinen Sequenzvorhersageproblemen gute Ergebnisse liefern wird.\n", "\n", "<img src=\"images\\vanillalstm.png\" alt=\"drawing\" style=\"width:100px;\"/>\n", "<p style=\"text-align: center;\">\n", "    Abb. 4 - Netzwerkstruktur f\u00fcr ein Vanilla-LSTM-Modell [3]\n", "</p>\n", "\n", "Das Vanilla LSTM hat die folgenden 5 attraktiven Eigenschaften [3], von denen die meisten bereits im Originalpaper [8] demonstriert wurden:\n", "- Sequenzklassifikation in Abh\u00e4ngigkeit von mehreren verteilten Eingabezeitschritten.\n", "- Speicherung von pr\u00e4zisen Eingangsbeobachtungen \u00fcber Tausende von Zeitschritten.\n", "- Sequenzvorhersage als Funktion von vorherigen Zeitschritten.\n", "- Robust gegen\u00fcber dem Einf\u00fcgen von zuf\u00e4lligen Zeitschritten auf der Eingangssequenz.\n", "- Robust gegen\u00fcber der Platzierung von Signaldaten auf der Eingangssequenz. "]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": ["# Import all libraries needed to implement a Vanilla LSTM\n", "from math import sqrt\n", "import numpy as np\n", "from numpy import array\n", "from numpy import mean\n", "from numpy import std\n", "import pandas as pd\n", "from pandas import DataFrame\n", "from pandas import concat\n", "from pandas import read_csv\n", "from sklearn.metrics import mean_squared_error\n", "import tensorflow as tf\n", "from tensorflow.python import keras\n", "from tensorflow.python.keras.models import Sequential\n", "from tensorflow.python.keras.layers import Dense\n", "from tensorflow.python.keras.layers import LSTM\n", "from matplotlib import pyplot\n", "from statsmodels.tsa.seasonal import seasonal_decompose\n", "from sklearn.preprocessing import MinMaxScaler\n", "\n", "# Prepare data\n", "series = read_csv('data/Load_DE_2017_2019.csv', header=0, index_col=0, parse_dates=True, squeeze=True, dayfirst=True)\n", "series = pd.to_numeric(series, errors='coerce').fillna(method='ffill', downcast='infer')\n", "values = series.values\n", "values = values.reshape((len(values), 1))\n", "scaler = MinMaxScaler(feature_range=(0, 1))\n", "scaler = scaler.fit(values)\n", "normalized = scaler.transform(values)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Nun werden wir die aus *Load_DE_2017_2019.csv* importierten Zeitreihen in ein geeignetes Format zur Modellierung von LSTM-Netzen konvertieren. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Train Test Split\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 6.3.5:</b> Schreiben Sie zun\u00e4chst eine Funktion, die den univariaten Datensatz in Trainings-/Tests\u00e4tze aufteilt. Verwenden Sie die Variable <i>n_test</i> (Anzahl der Datenpunkte im Testsatz) als Aufteilungsindex im Array. Der Eingabetyp ist ein Numpy-Array und die Ausgabe sollte ebenfalls ein aufgeteiltes Numpy-Array sein.\n", "</div>"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["# Split a univariate dataset into train/test sets\n", "def train_test_split(data:np.array, n_test:int):\n", "    # Input:\n", "        # data: ndarray \n", "        # n_test: integer, splitting index in the array\n", "    # Return: \n", "        # train, test: ndarray \n", "\n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["# Test your function\n", "dummy_array = np.arange(1,11,1)\n", "# To keep format the same\n", "dummy_array = np.expand_dims(dummy_array, axis=1)\n", "# Print transposed arrays for better visualization\n", "print('This is the (transposed) dummy_array', dummy_array.T)\n", "print('This is the (transposed) train data:', train_test_split(dummy_array, 2)[0][:].T)\n", "print('This is the (transposed) test data:', train_test_split(dummy_array, 2)[1][:].T)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Zeitreihen im \u00fcberwachten Lernen\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 6.3.6:</b> Schreiben Sie eine Funktion, die eine Liste in das Format des \u00fcberwachten Lernens umwandelt, d. h. in eine Eingabe- und Prognosesequenz. Betrachten Sie <i>n_in</i> als die Menge der Eingangsdatenelemente und <i>n_out</i> als die Menge der Elemente in der Prognosesequenz. Betrachten Sie die Sequenz als das gleiche Format wie das <i>dummy_array</i>.\n", "</div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ein Beispiel ist in der n\u00e4chsten Abbildung zu sehen: \n", "<img src=\"images\\series_to_supervised_example.png\" alt=\"drawing\" style=\"width:500px;\"/>"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["# Transform list into supervised learning format\n", "def series_to_supervised(data:np.array, n_in:int, n_out:int):\n", "    # Input:\n", "        # data: numpy ndarray \n", "        # n_in: rnn input data elements\n", "        # n_out: elements in the forecast sequence\n", "    # Output:\n", "        # numpy ndarray of size: (data_length - n_in - n_out + 1)x(n_in + n_out) \n", "        \n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["# Test your function\n", "dummy_array_sup = series_to_supervised(dummy_array, n_in=2, n_out=2)\n", "print(type(dummy_array_sup))\n", "print(dummy_array_sup)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Modellanpassung & Vorhersage\n", "\n", "Die Funktion zur Berechnung des mittleren quadratischen Fehlers der Vorhersage zu den tats\u00e4chlichen Datenwerten ist unten angegeben."]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["# Root mean squared error (rmse)\n", "def measure_rmse(actual:list, predicted:list)->float:\n", "    return sqrt(mean_squared_error(actual, predicted))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Mit der Funktion `model_fit()` k\u00f6nnen Sie die LSTM-Struktur aufbauen und das Modell trainieren. Diese Funktion hat als Eingabe eine *config*-Liste, die f\u00fcnf Modell-Hyperparameter enth\u00e4lt. Diese sind:\n", "\n", "- n_input: Die Anzahl der Lag-Beobachtungen, die als Eingabe f\u00fcr das Modell verwendet werden sollen.\n", "- n_Ausgang: Die Anzahl der Ausg\u00e4nge des Netzwerks.\n", "- n_Knoten: Die Anzahl der LSTM-Einheiten, die im Hidden Laye verwendet werden sollen.\n", "- n_epochs: Die Anzahl, wie oft das Modell dem gesamten Trainingsdatensatz ausgesetzt werden soll.\n", "- n_batch: Die Anzahl der Samples innerhalb einer Epoche, nach der die Gewichte aktualisiert werden.\n", "- n_freq: Die Frequenz der Reihe, die f\u00fcr die saisonale Zerlegung verwendet wird.\n", "\n", "Die Eingabe f\u00fcr das LSTM-Netzwerk muss eine dreidimensionale Struktur haben, die aus (Samples, Timesteps, Features) besteht. *Timesteps* stellt die Anzahl der Elemente aus der Vergangenheit dar, die als Eingabe an das Netzwerk gegeben werden. *Features* sind die Variablen, die als Eingabeelemente verwendet werden, um etwas vorherzusagen, die sogenannten Pr\u00e4diktoren. \n", "\n", "In unserem Fallbeispiel haben wir nur einen Pr\u00e4diktor als Eingabe, n\u00e4mlich die elektrische Lastreihe, daher _Features=1_. Die Anzahl der Zeitschritte in der Vergangenheit, die wir in unserem Eingabefenster ber\u00fccksichtigen, entspricht *n_input*. Die Anzahl der Fenster, die wir f\u00fcr die Vorhersage verwenden, ist gleich _Samples_. Daher muss die Form der Eingangsvariablen f\u00fcr unser LSTM [samples, n_input, 1] sein.\n", "\n", "Au\u00dferdem sollten Sie den Trainingsdatensatz deseasonalisieren, bevor Sie mit dem Trainingsprozess beginnen. Im Gegensatz zu MLPs und CNNs, die die Sequenzdaten nicht schrittweise einlesen, ist die Leistung des LSTM besser, wenn die Daten station\u00e4r sind. Als \u00dcbung k\u00f6nnen Sie jedoch beide F\u00e4lle, saisonale und deseasonalisierte Daten als Eingabe, ausprobieren. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 6.3.7:</b> Vervollst\u00e4ndigen Sie die Funktion <code>model_fit()</code> wie in den Kommentaren beschrieben.\n", "</div>"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": ["# Fit a model\n", "\n", "def model_fit(train:list, config:list):\n", "    \n", "    # Input:\n", "        # train: training data (seasonalized)\n", "        # config: list with model hyperparameters\n", "    # Output: \n", "        # model: trained model\n", "    \n", "    # Unpack config\n", "    n_input, n_output, n_nodes, n_epochs, n_batch, n_freq = config\n", "    \n", "    # Prepare data: deseasonalize the input data as preparation of the training dataset\n", "    # Please check the train shape afterwards\n", "    # train =  ??\n", "    \n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE\n", "    \n", "    # Change the format of the dataset to be used in supervised learning  \n", "    # data =  ??\n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE\n", "    \n", "    # Devide the data in features and labels\n", "    train_x, train_y = data[:, :-1], data[:, -1]\n", "    \n", "    # Reshape training features in the correct input format for LSTM networks\n", "    train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], 1))\n", "\n", "    # Init SequentialModel\n", "    model = Sequential()   \n", "\n", "    # Define one LSTM hidden layer followed by one dense hidden layer and \n", "    # one output layer as a dense layer with one node using model.add() (f.ex. as in Fig. 7 later in this task)\n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE\n", "    \n", "    # Compile Model\n", "    model.compile(loss='mse', optimizer='adam')\n", "    \n", "    # Fit Model\n", "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=1)\n", "    \n", "    return model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 6.3.8:</b> Die Funktion <code>model_predict()</code> erzeugt eine Vorhersage auf Basis eines vortrainierten Modells und Daten aus der Vergangenheit (Historie). Vervollst\u00e4ndigen Sie den folgenden Code wie in den Kommentaren beschrieben. \n", "</div>"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [], "source": ["# Forecast with a pre-fit model\n", "\n", "def model_predict(model, history:list, config:list):\n", "    # Input:\n", "        # model: model returned by model_fit()\n", "        # history: all available data from the past\n", "        # config: list with model hyperparameters\n", "    # Output: \n", "        # prediction: corrected prediction of the model with the seasonal term back\n", "        \n", "    # Unpack config\n", "    n_input, _, _, _, _, n_freq = config\n", "    \n", "    # Prepare data: Deseasonalize the input data as preparation of the test dataset  \n", "    # The correction term has to be used after predicting, in order to give back the seasonality to the data \n", "    # history =  ??\n", "    # correction =  ??\n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE    \n", "    \n", "    x_input = array(history[-n_input:]).reshape((1, n_input, 1))\n", "    \n", "    # Forecast\n", "    yhat = model.predict(x_input, verbose=0)\n", "    \n", "    return correction[-n_freq] + yhat[0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Walk Forward Validierung\n", "\n", "Die `walk_forward_validation()` f\u00fchrt die Trainings- und Testprozesse durch, d. h. sie passt das Modell an die Trainingsdaten an, erzeugt dann Vorhersagen aus dem Testdatensatz und berechnet den Vorhersagefehler f\u00fcr eine Posterior-Analyse. \n", "\n", "Der hier zu programmierende Ansatz erzeugt Vorhersagen von genau einem Zeitschritt nach dem Ende des Trainingsdatensatzes. Daher wird die Historie-Variable f\u00fcr `model_predict()` mit Trainingsdaten initialisiert und mit dem Testdatensatz verkettet. Sie k\u00f6nnen einen anderen Ansatz versuchen, bei dem das Modell mit einem Historie-Array getestet wird, das nur Testdaten enth\u00e4lt. Beide werten das Modell auf unterschiedliche Weise aus."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe/Frage 6.3.9:</b> Schreiben Sie bitte eine Analyse der Vor- und Nachteile beider L\u00f6sungen und erkl\u00e4ren Sie, warum wir bei der Prognose von Zeitreihen den einen oder den anderen Ansatz verwenden sollten. \n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", "", "", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 6.3.10:</b> Verwenden Sie die Funktionen, die Sie zuvor programmiert haben, um den folgenden Code f\u00fcr <code>walk_forward_validation()</code> zu vervollst\u00e4ndigen. \n", "</div>"]}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [], "source": ["# walk-forward validation for univariate data\n", "def walk_forward_validation(data:list, n_test:int, cfg:list):\n", "    # Input:\n", "        # data: time series in ndarray format\n", "        # n_test: integer, splitting index in the array\n", "        # cfg: list of model hyperparameters\n", "    # Output:\n", "        # error: rmse of predictions from the test set\n", "        # predictions: predicted values\n", "        # test_values: data values, ground-truth\n", "    \n", "    # Initialize the predictions array\n", "    predictions = list()\n", "    \n", "    # Split dataset\n", "    # train, test = ??\n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE    \n", "    \n", "    # Fit the model\n", "    # model = ??\n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE \n", "    \n", "    # Initialize history array with training dataset as historical data\n", "    history = [x for x in train]\n", "    \n", "    print('The model starts predicting...')\n", "    \n", "    # Step over each time-step in the test set\n", "    for i in range(len(test)):\n", "        \n", "        # Make forecast for history\n", "        # yhat = ??\n", "        # STUDENT CODE HERE\n", "\n", "        # STUDENT CODE until HERE \n", "                \n", "        # Store forecast in list of predictions\n", "        predictions.append(yhat)\n", "        \n", "        # Add actual observation to history for the next loop\n", "        history.append(test[i])\n", "        \n", "    # Estimate prediction error\n", "    error = measure_rmse(test, predictions)\n", "    \n", "    print('Prediction error:  %.3f' % error)\n", "    return error, predictions, test"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Schlussfolgerung Vanilla LSTM\n", "\n", "Der folgende Code f\u00fchrt Ihr LSTM-Vanilla-Modell aus. Es steht Ihnen frei, die Parameter im *config*-Array zu \u00e4ndern, die normalisierten Daten f\u00fcr das Training zu verwenden und auch die Art des f\u00fcr den Trainingsprozess verwendeten Optimierers zu \u00e4ndern. \n", "\n", "F\u00fcr die ersten Testausf\u00fchrungen empfehlen wir, nur einen Teil des Datensatzes zu verwenden. Ansonsten kann es eine Weile dauern. Nachdem Sie sicher sind, dass der Code wie erwartet funktioniert, f\u00fchren Sie ihn f\u00fcr den gesamten Datensatz aus."]}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [], "source": ["# data = series.values  ## uncomment to test for the whole dataset\n", "data = normalized[:2976] ## Executing first with 31 days * 24 hours * 60 mins/15 mins = 2976 \n", "# data split: Forecasting the load in a day\n", "# n_test = int(0.7*series.size) ## Testing with 30% of the dataset\n", "n_test = 384 ## Testing with the last 4 days = 384 elements\n", "# Define config, (n_input, n_output, n_nodes, n_epochs, n_batch, n_freq = config)\n", "config = [48, 1, 50, 1, 10, 96]\n", "# Fit and evaluate the model n_repeats times\n", "score, predictions, y_test = walk_forward_validation(data, n_test, config)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 6.3.11:</b> K\u00f6nnen Sie erkl\u00e4ren, warum das Modell in der Lage ist, die n\u00e4chste 15-min\u00fctige elektrische Last besser vorherzusagen, indem es nur einen einzigen Eingabeschritt aus der Vergangenheit verwendet? Hinweis: Was ist der Unterschied zu einem normalen feed forward neuronalen Netz?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 6.3.12:</b> Importieren Sie matplotlib und plotten Sie die Vorhersagen und den Testsatz in einem Plot, um eine Intuition \u00fcber die Vorhersage und Ihr Modell zu bekommen.\n", "</div>"]}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Anf\u00e4ngerfehler\n", "Nachdem Sie Ihr Modell einmal mit Hilfe des Datensatzes angepasst und bewertet haben, neigen Anf\u00e4ngerInnen zu denken, dass der f\u00fcr diese Modellkonfiguration erstellte Skill-Bericht fertig ist. Wenn jedoch dieselbe Modellarchitektur mehrmals trainiert wird, ist die erhaltene Modellf\u00e4higkeit unterschiedlich. Der Grund daf\u00fcr ist die stochastische Eigenschaft des Deep Learnings. Modelle wie LSTMs verwenden bei der Anpassung Zuf\u00e4lligkeiten, wie z. B. zuf\u00e4llige Anfangsgewichte oder die Umverteilung der Daten nach jeder Trainingsepoche w\u00e4hrend des stochastischen Gradientenabstiegs."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 6.3.13:</b> Bewerten Sie die Zuf\u00e4lligkeit des Trainingsergebnisses des Vanilla LSTM, das Sie bereits programmiert haben. Probieren Sie es aus, indem Sie die Funktion <code>repeat_evaluate()</code> schreiben, wobei die Funktion <code>walk_forward_validation()</code> n_repeats mal ausgef\u00fchrt wird. Alle Ergebnisse sollen in einem Array namens <i>scores</i> gespeichert und zur\u00fcckgegeben werden. \n", "</div>"]}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [], "source": ["# Repeat evaluation of a LSTM model\n", "def repeat_evaluate(data, config, n_test, n_repeats=30):\n", "    # Input:\n", "        # data: time series in ndarray format\n", "        # config: list of model hyperparameters\n", "        # n_test: integer, splitting index in the array\n", "        # n_repeats: number of times walk_forward_validation() has to be executed\n", "    # Output:\n", "        # scores: list object of errors returned by walk_forward_validation()\n", "        \n", "    # Fit and evaluate the model n times\n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE \n", "    return scores\n", "    \n", "# data = series.values  ## uncomment to test for the whole dataset\n", "data = normalized[:2976] ## Executing first with 31 days * 24 hours * 60 mins/15 mins = 2976 \n", "# data split\n", "# n_test = int(0.7*series.size)  ## Testing with 30% of the dataset\n", "n_test = 384 ## Testing with the last 4 days = 384 elements\n", "# Define config, with config = [n_input, n_output, n_nodes, n_epochs, n_batch, n_freq]\n", "config = [48, 1, 50, 10, 10, 96]\n", "# Fit and evaluate the model n_repeats times\n", "scores = repeat_evaluate(data, config, n_test, n_repeats=10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### F\u00e4higkeitssch\u00e4tzung eines Stochastischen Modells\n", "Da jedes Mal, wenn ein Modell angepasst wird, eine gewisse Zuf\u00e4lligkeit im F\u00e4higkeitsscore zu beobachten ist, m\u00fcssen mehrere Durchl\u00e4ufe durchgef\u00fchrt werden, um eine Vorstellung von der Stabilit\u00e4t des Modells zu bekommen. Die endg\u00fcltige Modellf\u00e4higkeit muss als Mittelwert und Varianz der Werte angegeben werden. Dies ergibt eine robuste Sch\u00e4tzung des Modells. <br>\n", "Jedes Modelltraining muss auf dem gleichen Trainingsdatensatz und mit der gleichen Architektur durchgef\u00fchrt werden, um nur die intrinsischen Trainingsver\u00e4nderungen im Modell zu bewerten. Die Anzahl der Durchl\u00e4ufe h\u00e4ngt von der Zeit ab, die das Modell zum Trainieren ben\u00f6tigt. Mehr Wiederholungen erm\u00f6glichen ein besseres Verst\u00e4ndnis der Variabilit\u00e4t der Modelll\u00f6sung.<br>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 6.3.14:</b> Vervollst\u00e4ndigen Sie die Funktion <code>summarize_scores()</code>, die als Eingabe das von <code>repeat_evaluate()</code> erzeugte Array mit den Ergebnissen erh\u00e4lt sowie Mittelwert und Standardabweichung der Ergebnisse ausgibt. Diese Funktion sollte auch in der Lage sein, ein Boxplot der Ergebnisse zu erstellen. \n", "</div>"]}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [], "source": ["# Summarize model performance\n", "def summarize_scores(name, scores):\n", "    # Input:\n", "        # name: string, model name\n", "        # scores: repeat_evaluate() output array\n", "    # Output: \n", "        # none\n", "        \n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE \n", "    \n", "# Summarize scores\n", "summarize_scores('lstm', scores)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Gestapeltes LSTM\n", "\n", "Das Vanilla-LSTM, das nur ein Hidden Layer enth\u00e4lt, kann einige einfache Probleme l\u00f6sen. Um kompliziertere Probleme zu l\u00f6sen, \"m\u00fcssen wir tiefer gehen\" (falls der Begriff *Deep Learning* nicht klar war, jetzt ist er es). Durch das Stapeln mehrerer Hidden Layers kann das LSTM-Netz komplexere Merkmale des Systems (Zeitreihe, Bild, Text, Video usw.) lernen und eine bessere Ausgabe (Vorhersage, Text, Sequenz usw.) erzeugen.\n", "\n", "<img src=\"images\\we-have-to-go-deeper.png\" alt=\"drawing\" style=\"width:500px;\"/>\n", "<p style=\"text-align: center;\">\n", "    Abb. 5 - Um komplexere Probleme zu l\u00f6sen, ist es wichtig, das Netz vertikal zu erweitern, d.h. Schichten zu stapeln. [Bildreferenz: Film Inception (2010)]\n", "</p>\n", "\n", "Das gestapelte LSTM ist ein Modell mit mehreren versteckten LSTM-Schichten, wobei jede Schicht mehrere Speicherzellen enth\u00e4lt. Da LSTMs mit Sequenzdaten arbeiten, bedeutet dies, dass das Hinzuf\u00fcgen von Schichten zus\u00e4tzliche Abstraktionsebenen der Input Beobachtungen \u00fcber die Zeit hinzuf\u00fcgt. [3] RNNs haben von Natur aus eine gro\u00dfe zeitliche Tiefe, da ihr versteckter Zustand (engl. hidden state) eine Funktion aller vorherigen versteckten Zust\u00e4nde ist. Sie k\u00f6nnen auch von der r\u00e4umlichen Tiefe profitieren, d. h. von der Stapelung mehrerer rekurrenter versteckter Schichten \u00fcbereinander. [9] Abbildung 6 zeigt ein gestapeltes LSTM-Netz mit zwei Hidden Layers. \n", "\n", "<img src=\"images\\stackedlstm.png\" alt=\"drawing\" style=\"width:100px;\"/>\n", "<p style=\"text-align: center;\">\n", "    Abb. 6 - Netzwerkstruktur f\u00fcr ein gestapeltes LSTM-Modell. Die Anzahl der LSTM-Schichten h\u00e4ngt von der Anwendung ab. [3]\n", "</p>\n", "\n", "Das gestapelte LSTM-Modell erwartet eine Liste von sechs Modell-Hyperparametern, welche sind:\n", "\n", "- n_input: Die Anzahl der Verz\u00f6gerungsbeobachtungen, die als Input f\u00fcr das Modell verwendet werden sollen.\n", "- n_output: Die Anzahl der Ausgaben des Netzwerks.\n", "- n_layers: Die Anzahl der versteckten LSTM-Schichten.\n", "- n_nodes: Die Anzahl der LSTM-Einheiten in jeder versteckten Schicht. Dieser Parameter muss ein Array mit dem entsprechenden Wert pro Schicht sein.\n", "- n_epochs: Die Anzahl, wie oft das Modell dem gesamten Trainingsdatensatz ausgesetzt werden soll.\n", "- n_batch: Die Anzahl der Datenpunkte innerhalb einer Epoche, nach der die Gewichte aktualisiert werden.\n", "- n_freq: Die Frequenz der Reihe, die f\u00fcr die saisonale Zerlegung verwendet wird.\n", "\n", "Jede LSTM-Speicherzelle ben\u00f6tigt eine 3D-Eingabe. Wenn ein LSTM eine Eingangssequenz von Zeitschritten verarbeitet, wird jede Speicherzelle\n", "einen einzigen Wert f\u00fcr die gesamte Sequenz als 2D-Array aus. Um LSTM-Schichten zu stapeln, m\u00fcssen wir die Konfiguration der vorherigen LSTM-Schicht \u00e4ndern, um ein 3D-Array als Eingabe f\u00fcr die nachfolgende Schicht auszugeben. Dies ist m\u00f6glich, indem man das Argument *return_sequences*\n", "auf der Ebene auf True setzt (Standard ist False). Dadurch wird eine Ausgabe f\u00fcr jeden Eingabezeitschritt zur\u00fcckgegeben und ein 3D-Array bereitgestellt. Abbildung 7 zeigt, wie der Code f\u00fcr zwei versteckte LSTM-Schichten aussehen sollte. \n", "\n", "<img src=\"images\\stacking_lstm_code.png\" alt=\"drawing\" style=\"width:700px;\"/>\n", "<p style=\"text-align: center;\">\n", "    Abb. 7 - Code zur Definition eines gestapelten LSTM mit 2 Hidden Layers. [3]\n", "</p>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 6.3.15:</b> \u00c4ndern Sie die Funktionen (<code>model_fit()</code>, <code>model_predict()</code>), die Sie zuvor geschrieben haben (f\u00fcr den Vanilla LSTM), um mehrere LSTM-Schichten im Modell zu haben. F\u00fcllen Sie die folgende Zelle mit Ihrem neuen Code.\n", "\n", "\n", "\n", "<ul>\n", "<li> Hinweis 1: Seien Sie vorsichtig mit der Definition von n_nodes; in diesem Fall ist es ein Array mit der Anzahl der LSTM-Einheiten in jeder versteckten Schicht und nicht mehr ein einzelner Integer-Wert wie zuvor.\n", "<li>Hinweis 2: <code>model_predict()</code> muss nur die Konfiguration richtig entpacken.\n", "\n", "\n", "</li>\n", "</ul>\n", "</div>"]}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [], "source": ["# STUDENT CODE HERE\n", "\n", "# STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 6.3.16:</b> Nehmen wir an, Sie wollen mit demselben Netz mehrere Zeitschritte vorhersagen. Welche Variable oder Parameter des von Ihnen programmierten gestapelten LSTM-Netzes m\u00fcssen Sie anpassen, um mehrere Ausg\u00e4nge statt nur einem zu haben?  \n", "</div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Diagnose von Under- und Overfitting\n", "Eine der wichtigsten Pr\u00fcfungen, die Sie an Ihrem Modell durchf\u00fchren m\u00fcssen, ist die \u00dcberpr\u00fcfung auf Under- und Overfitting. Dazu ben\u00f6tigen Sie die Trainings- und Validierungsverlustfunktionen, die von der Keras-Methode `.fit()` Ihres Modells erzeugt werden. Diese Werte werden in dem *History*-Objekt gespeichert, das von dieser Funktion zur\u00fcckgegeben wird. <br> \n", "Normalerweise enth\u00e4lt das History-Objekt die Trainings-/Validierungsgenauigkeit und die Verlustfunktionen, aber dies kann sich von L\u00f6sung zu L\u00f6sung \u00e4ndern. Um zu \u00fcberpr\u00fcfen, was das History-Objekt enth\u00e4lt, verwenden Sie\n", "````python \n", "# list all data in history\n", "print(history.history.keys())\n", ">> ['acc', 'loss', 'val_acc', 'val_loss']\n", "```"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 6.3.17:</b> \u00c4ndern Sie die Funktion <code>model_fit()</code>, um die Verlustfunktion f\u00fcr den Trainings- und den Validierungsprozess zu sammeln und darzustellen.\n", "<ul>\n", "\n", "<li>Die Ausgabe der Historie erhalten Sie, indem Sie einfach <code>model_metric = model.fit(...)</code> verwenden.\n", "    \n", "\n", "<li>\n", "    Da in der Funktion <code>walk_forward_validation()</code> bereits eine Variable namens <i>history</i> verwendet wird, um vergangene Daten zu speichern, soll hier der Name <b>model_metric</b> f\u00fcr das History-Ausgabeobjekt der Keras-Methode <code>.fit()</code> verwendet werden. \u00dcbergeben Sie einfach <b>model_metric</b> durch <code>walk_forward_validation()</code>.\n", "\n", "<li>Um den Trainingsdatensatz innerhalb der <code>model_fit()</code>-Funktion in einen Validierungssatz aufzuteilen, verwenden Sie den Parameter <i>validation_split</i> aus der Keras-Methode <code>.fit()</code>. Ein Splitting-Verh\u00e4ltnis von einem Drittel der Gesamtmenge sollte ausreichen.\n", "\n", "</ul>\n", "\n", "</div>"]}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [], "source": ["def model_fit(train, config):\n", "    # Input:\n", "        # train: time series data in ndarray format. Shape: (time series length x 1)\n", "        # config: list of model hyperparameters\n", "    # Output:\n", "        # model: trained LSTM model\n", "        # model_metric: History output object of the Keras function fit()\n", "        \n", "\n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE \n", " \n", "def walk_forward_validation(data, n_test, cfg):\n", "    # Input:\n", "        # data: time series in ndarray format\n", "        # n_test: integer, splitting index in the array\n", "        # cfg: list of model hyperparameters\n", "    # Output:\n", "        # error: rmse of predictions from the test set\n", "        # model_metric: History output object of model_fit()\n", "\n", "    n_input, n_output, n_layers, n_nodes, n_epochs, n_batch, n_freq = cfg\n", "\n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE\n", "    \n", "# data = series.values  ## uncomment to test for the whole dataset\n", "data = normalized[:2976] ## Executing first with 31 days * 24 hours * 60 mins/15 mins = 2976 \n", "\n", "# Data split\n", "# n_test = int(0.7*series.size)  ## Testing with 30% of the dataset\n", "n_test = 384 ## Testing with the last 4 days = 384 elements\n", "\n", "# Define config: [n_input, n_output, n_layers, n_nodes, n_epochs, n_batch, n_freq]\n", "config = [48, 1, 3, [50, 30, 50], 10, 10, 96]\n", "\n", "score, predictions, y_test, model_metric = walk_forward_validation(data, n_test, config)\n", "\n", "# Plot train and validation loss\n", "pyplot.plot(model_metric.history['loss'])\n", "pyplot.plot(model_metric.history['val_loss'])\n", "pyplot.title('model train vs validation loss')\n", "pyplot.ylabel('loss')\n", "pyplot.xlabel('epoch')\n", "pyplot.legend(['train', 'validation'], loc='upper right')\n", "pyplot.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 6.3.18:</b> Analysieren Sie die Graphen, die Sie bei der Analyse des Under-/Overfittings erhalten haben. Was k\u00f6nnen Sie \u00fcber Ihr Modell sagen? W\u00fcrden Sie etwas \u00e4ndern, um Ihre Ergebnisse zu verbessern? Wenn ja, nehmen Sie die \u00c4nderungen vor und schreiben Sie hier eine kurze Dokumentation \u00fcber Ihre Beobachtungen.\n", "<ul>\n", "\n", "<li> Hinweis: Wenn Sie mehr \u00fcber die Analyse der Trainings- und Validierungsverlustgraphen wissen m\u00f6chten, k\u00f6nnen Sie sich das folgende <a href=\"https://www.tensorflow.org/tutorials/keras/overfit_and_underfit\">Tutorial zu Over- und Underfitting von Tensorflow</a> ansehen.\n", "</ul>\n", "</div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Einige abschlie\u00dfende Hinweise \n", "\n", "Bevor wir die Einf\u00fchrung in LSTMs beenden, sollten noch einige Hinweise zu den Hyperparametern des Netzes beachtet werden:\n", "\n", "- Das Problem des explodierenden Gradienten kann dort bleiben: LSTMs haben nicht das Problem der verschwindenden Gradienten wie die konventionellen RNNs. Dennoch kann das Problem des explodierenden Gradienten auch bei LSTM-Modellen auftreten. Daher ist das Beschneiden der Gradienten eine gute L\u00f6sung f\u00fcr dieses Problem (weitere Informationen finden Sie in <a href=\"https://machinelearningmastery.com/exploding-gradients-in-neural-networks\">diesem Artikel</a>).\n", "- Initialisieren Sie die Forget-Gates mit einem hohen Bias, um das Erinnern zu Beginn des Trainingsprozesses zu f\u00f6rdern. \n", "- Bedenken Sie, dass die L2-Regularisierung bei der Arbeit mit LSTM-Netzen manchmal nicht hilfreich ist.\n", "- Es ist immer gut, Dropout im rekurrenten Teil des Netzes zu implementieren (nicht in der Zeitachse des Netzes)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Referenzen\n", "[1] J. Brownlee, Introduction to time series forecasting with python: how to prepare data and develop models to predict the future. 2018.<br>\n", "[2] J. Brownlee, Deep Learning for Time Series Forecasting: predict the Future with MLPs, CNNs and LSTMs in Python. 2018.<br>\n", "[3] J. Brownlee, Long Short-Term Memory Networks With Python: Develop Sequence Prediction Models With Deep Learning. 2017.<br>\n", "[4] G. Shmueli, Practical Time Series Forecasting with R: A Hands-On Guide, 2nd ed. Axelrod Schnall Publishers, 2016.<br>\n", "[5] I. Sutskever, O. Vinyals, and Q. V. Le, \u201cSequence to Sequence Learning with Neural Networks,\u201d in Neural Information Processing Systems Conference, 2014.<br>\n", "[6] H. Sak, A. Senior, and F. Beaufays, \u201cLong Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling.\u201d<br>\n", "[7] K. Greff, R. K. Srivastava, J. Koutn\u00edk, B. R. Steunebrink, and J. Schmidhuber, \u201cLSTM: A Search Space Odyssey,\u201d Trans. Neural Networks Learn. Syst., 2017.<br>\n", "[8] S. Hochreiter and Ju. Schmidhuber, \u201cLong Short-Term Memory,\u201d Neural Comput., vol. 9, no. 8, pp. 1735\u20131780, 1997.<br>\n", "[9] A. Graves, A. Mohamed and G. Hinton, \"Speech Recognition With Deep Recurrent Neural Networks\", 2013. <br>\n", "[10] PennState Eberly College of Science, \u201c5.1 Decomposition Models | STAT 510,\u201d 2018. [Online]. Available: https://onlinecourses.science.psu.edu/stat510/node/69/. [Accessed: 14-Nov-2018].<br>\n", "[11] A. Karpathy: The Unreasonable Effectiveness of Recurrent Neural Networks. http://karpathy.github.io/2015/05/21/rnn-effectiveness/. Version: 2015. [Last Checked: 28.09.2018]. <br>\n", "[12] J. Brownlee: How to develop Deep Learning Models for univariate time series forecasting. https://machinelearningmastery.com/how-to-develop-deep-learning-models-for-univariate-time-series-forecasting/. Version: October, 2018. [Last Checked: 19.05.2019]."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.10"}}, "nbformat": 4, "nbformat_minor": 4}